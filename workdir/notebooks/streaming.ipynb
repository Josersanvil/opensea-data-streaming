{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://f4fdfd739436:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Streaming</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff7c3fc590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Streaming\")  # type: ignore\n",
    "    .master(\"spark://spark:7077\")\n",
    "    .config(\"spark.executor.cores\", 1)\n",
    "    .config(\"spark.executor.instances\", 1)\n",
    "    # .config(\"spark.cores.max\", 1)\n",
    "    # Set configuration for Notebook display\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    # Log level to WARN to avoid huge logs\n",
    "    .config(\"spark.logConf\", False)\n",
    "    .getOrCreate()\n",
    ")\n",
    "# spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- collection_slug: string (nullable = true)\n",
      " |-- sent_at: timestamp (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- item_name: string (nullable = true)\n",
      " |-- item_url: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- item_blockchain: string (nullable = true)\n",
      " |-- listing_date: string (nullable = true)\n",
      " |-- listing_type: string (nullable = true)\n",
      " |-- from_account: string (nullable = true)\n",
      " |-- to_account: string (nullable = true)\n",
      " |-- payment_symbol: string (nullable = true)\n",
      " |-- eth_price: string (nullable = true)\n",
      " |-- usd_price: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data from the topic as a DataFrame.\n",
    "raw_topic_df = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:19092\")\n",
    "    .option(\"subscribe\", \"OpenSeaRawEvents\")\n",
    "    .load()\n",
    ")\n",
    "raw_topic_df.printSchema()\n",
    "parsed_topic_data = raw_topic_df.selectExpr(\n",
    "    \"CAST(value as string) as json_value\",\n",
    "    \"timestamp as processed_at\",\n",
    ")\n",
    "opensea_events = parsed_topic_data.select(\n",
    "    F.get_json_object(\"json_value\", \"$.payload.event_type.slug\").alias(\"event_type\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.collection.slug\").alias(\"collection_slug\"),\n",
    "    F.to_timestamp(F.get_json_object(\"json_value\", \"$.payload.sent_at\")).alias(\"sent_at\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.status\").alias(\"status\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.item.metadata.name\").alias(\"item_name\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.item.permalink\").alias(\"item_url\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.item.metadata.image_url\").alias(\"image_url\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.item.chain.name\").alias(\"item_blockchain\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.listing_date\").alias(\"listing_date\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.listing_type\").alias(\"listing_type\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.from_account.address\").alias(\"from_account\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.to_account.address\").alias(\"to_account\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.payment_token.symbol\").alias(\"payment_symbol\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.payment_token.eth_price\").alias(\"eth_price\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.payment_token.usd_price\").alias(\"usd_price\"),\n",
    "    F.get_json_object(\"json_value\", \"$.payload.payload.quantity\").alias(\"quantity\"),\n",
    ")\n",
    "opensea_events.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- collection_slug: string (nullable = true)\n",
      " |-- sent_at: timestamp (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- item_name: string (nullable = true)\n",
      " |-- item_url: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- item_blockchain: string (nullable = true)\n",
      " |-- listing_date: string (nullable = true)\n",
      " |-- listing_type: string (nullable = true)\n",
      " |-- from_account: string (nullable = true)\n",
      " |-- to_account: string (nullable = true)\n",
      " |-- payment_symbol: string (nullable = true)\n",
      " |-- eth_price: string (nullable = true)\n",
      " |-- usd_price: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sold_items = opensea_events.filter(F.col(\"event_type\") == \"item_sold\")\n",
    "sold_items.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- collection_slug: string (nullable = true)\n",
      " |-- sent_at: timestamp (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- item_name: string (nullable = true)\n",
      " |-- item_url: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- item_blockchain: string (nullable = true)\n",
      " |-- listing_date: string (nullable = true)\n",
      " |-- listing_type: string (nullable = true)\n",
      " |-- from_account: string (nullable = true)\n",
      " |-- to_account: string (nullable = true)\n",
      " |-- payment_symbol: string (nullable = true)\n",
      " |-- eth_price: string (nullable = true)\n",
      " |-- usd_price: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transferred_items = opensea_events.withColumn(\n",
    "    \"quantity\",\n",
    "    F.when(F.col(\"quantity\").cast(\"int\") > 0, F.col(\"quantity\").cast(\"int\")).otherwise(\n",
    "        0\n",
    "    ),\n",
    ")\n",
    "transferred_items.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_time_frame = \"1 minute\" # The time for each aggregation\n",
    "time_frame_txt = \"_\".join(agg_time_frame.split())\n",
    "agg_update_time = \"30 seconds\" # The time for each update of the aggregation\n",
    "# Every <agg_update_time> we will calculate the aggregation for the last <agg_time_frame>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_topic = \"OpenSeaEnrichedGlobalEvents\"\n",
    "topic_checkpoint_folder = f\"s3a://processed-data/checkpoints/topics/{kafka_topic}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_checkpoint_folder = f\"{topic_checkpoint_folder}/MarketTransactionsMetrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_time_window = F.window(\"sent_at\", agg_time_frame, agg_update_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window_start: timestamp (nullable = true)\n",
      " |-- window_end: timestamp (nullable = true)\n",
      " |-- transfers_count: long (nullable = false)\n",
      " |-- items_transferred_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowed_transactions = (\n",
    "    transferred_items\n",
    "    .withWatermark(\"sent_at\", agg_update_time)\n",
    "    .groupBy(agg_time_window)\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"transfers_count\"),\n",
    "        F.sum(\"quantity\").alias(\"items_transferred_count\"),\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"window.start\").alias(\"window_start\"),\n",
    "        F.col(\"window.end\").alias(\"window_end\"),\n",
    "        \"transfers_count\",\n",
    "        \"items_transferred_count\",\n",
    "    )\n",
    ")\n",
    "windowed_transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- metric: string (nullable = false)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- value: long (nullable = true)\n",
      " |-- collection: void (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowed_transactions_events = windowed_transactions.unpivot(\n",
    "    [\"window_start\", \"window_end\"],\n",
    "    [\"transfers_count\", \"items_transferred_count\"],\n",
    "    \"metric\",\n",
    "    \"value\",\n",
    ").select(\n",
    "    F.concat(\"metric\", F.lit(f\"__{time_frame_txt}\")).alias(\"metric\"),\n",
    "    F.col(\"window_end\").alias(\"timestamp\"),\n",
    "    \"value\",\n",
    "    F.lit(None).alias(\"collection\"),\n",
    ")\n",
    "windowed_transactions_events.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_metrics_messages = windowed_transactions_events.select(\n",
    "    F.to_json(F.struct(\"*\"), options={\"ignoreNullFields\": False}).alias(\"value\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/21 09:49:58 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "24/07/21 09:49:59 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0xffff74142e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send events to Kafka Topic\n",
    "transactions_metrics_query = (\n",
    "    transactions_metrics_messages.writeStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:19092\")\n",
    "    .option(\n",
    "        \"checkpointLocation\",\n",
    "        query_checkpoint_folder,\n",
    "    )\n",
    "    .option(\"topic\", kafka_topic)\n",
    ")\n",
    "transactions_metrics_query.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions_metrics_query_console = (\n",
    "#     transactions_metrics_messages.writeStream.outputMode(\"append\")\n",
    "#     .format(\"console\")\n",
    "#     .option(\"truncate\", False)\n",
    "#     .start()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marketplace Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_checkpoint_folder = f\"{topic_checkpoint_folder}/MarketDataAggregations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_time_window = F.window(\"sent_at\", agg_time_frame, agg_update_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window_start: timestamp (nullable = true)\n",
      " |-- window_end: timestamp (nullable = true)\n",
      " |-- usd_volume: double (nullable = true)\n",
      " |-- sales_count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sold_items_windowed = (\n",
    "    sold_items.withWatermark(\"sent_at\", agg_update_time)\n",
    "    .groupBy(agg_time_window)\n",
    "    .agg(\n",
    "        F.sum(\"usd_price\").alias(\"usd_volume\"),\n",
    "        F.count(\"*\").alias(\"sales_count\"),\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"window.start\").alias(\"window_start\"),\n",
    "        F.col(\"window.end\").alias(\"window_end\"),\n",
    "        \"usd_volume\",\n",
    "        \"sales_count\",\n",
    "    )\n",
    ")\n",
    "sold_items_windowed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- metric: string (nullable = false)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- collection: void (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sold_items_windowed_events = sold_items_windowed.select(\n",
    "    F.lit(f\"total_volume__{time_frame_txt}\").alias(\"metric\"),\n",
    "    F.col(\"window_end\").alias(\"timestamp\"),\n",
    "    F.col(\"usd_volume\").alias(\"value\"),\n",
    "    F.lit(None).alias(\"collection\"),\n",
    ")\n",
    "sold_items_windowed_events.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/21 09:50:00 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0xffff7c3f2a10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send events to Kafka Topic\n",
    "sales_volume_query = (\n",
    "    sold_items_windowed_events.select(F.to_json(F.struct(\"*\")).alias(\"value\"))\n",
    "    .writeStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:19092\")\n",
    "    .option(\n",
    "        \"checkpointLocation\",\n",
    "        query_checkpoint_folder,\n",
    "    )\n",
    "    .option(\"topic\", kafka_topic)\n",
    ")\n",
    "sales_volume_query.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_checkpoint_folder = f\"{topic_checkpoint_folder}/MarketTopCollections/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'window(sent_at, 60000000, 30000000, 0) AS window'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_time_window = F.window(\"sent_at\", agg_time_frame, agg_update_time)\n",
    "agg_time_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- collection_slug: string (nullable = true)\n",
      " |-- window: struct (nullable = true)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- usd_volume: double (nullable = true)\n",
      " |-- sales_count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sold_items.groupBy(\"collection_slug\", agg_time_window).agg(\n",
    "    F.sum(\"usd_price\").alias(\"usd_volume\"),\n",
    "    F.count(\"*\").alias(\"sales_count\"),\n",
    ").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- collection_slug: string (nullable = true)\n",
      " |-- window_start: timestamp (nullable = true)\n",
      " |-- window_end: timestamp (nullable = true)\n",
      " |-- usd_volume: double (nullable = true)\n",
      " |-- sales_count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_collections_windowed = (\n",
    "    sold_items.withWatermark(\"sent_at\", agg_update_time)\n",
    "    .groupBy(\"collection_slug\", agg_time_window)\n",
    "    .agg(\n",
    "        F.sum(\"usd_price\").alias(\"usd_volume\"),\n",
    "        F.count(\"*\").alias(\"sales_count\"),\n",
    "    )\n",
    "    .select(\n",
    "        \"collection_slug\",\n",
    "        F.col(\"window.start\").alias(\"window_start\"),\n",
    "        F.col(\"window.end\").alias(\"window_end\"),\n",
    "        \"usd_volume\",\n",
    "        \"sales_count\",\n",
    "    )\n",
    ")\n",
    "top_collections_windowed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- metric: string (nullable = false)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- collection: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_collections_windowed_events = top_collections_windowed.select(\n",
    "    F.lit(f\"top_collections_by_volume__{time_frame_txt}\").alias(\"metric\"),\n",
    "    F.col(\"window_end\").alias(\"timestamp\"),\n",
    "    F.col(\"usd_volume\").alias(\"value\"),\n",
    "    F.col(\"collection_slug\").alias(\"collection\"),\n",
    ")\n",
    "top_collections_windowed_events.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/21 09:50:01 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0xffff740ff150>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/21 09:50:33 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "24/07/21 09:51:10 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "24/07/21 09:51:31 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "24/07/21 10:27:15 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:15 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:15 WARN NetworkClient: [AdminClient clientId=adminclient-3] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:15 WARN NetworkClient: [AdminClient clientId=adminclient-3] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:15 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:15 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:30 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:30 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:30 WARN NetworkClient: [AdminClient clientId=adminclient-3] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:33 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:33 WARN NetworkClient: [AdminClient clientId=adminclient-3] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:33 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:36 WARN NetworkClient: [AdminClient clientId=adminclient-3] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:36 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:36 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:39 WARN NetworkClient: [AdminClient clientId=adminclient-3] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:39 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:39 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:42 WARN NetworkClient: [AdminClient clientId=adminclient-3] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:42 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:42 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:46 WARN NetworkClient: [AdminClient clientId=adminclient-3] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:46 WARN NetworkClient: [AdminClient clientId=adminclient-1] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:46 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 1 (kafka/172.18.0.10:19092) could not be established. Broker may not be available.\n",
      "24/07/21 10:27:47 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka: Name or service not known\n",
      "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
      "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:47 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:887)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:47 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:47 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:48 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:48 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:48 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:49 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:49 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:49 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:49 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:49 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:50 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:50 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:51 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:51 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:51 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:52 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:52 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:53 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:53 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:53 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:53 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:54 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:54 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:54 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:55 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:55 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:55 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:56 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:57 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:57 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:57 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka: Name or service not known\n",
      "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
      "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:58 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:58 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:58 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:58 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:59 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:59 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:27:59 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:00 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:00 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:01 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:01 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:01 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:02 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:02 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:02 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:02 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:03 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:03 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:03 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:04 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:04 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:04 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:05 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:05 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:05 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:06 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:06 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:06 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:07 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:07 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka: Name or service not known\n",
      "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
      "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:07 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:08 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:08 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:08 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:09 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:09 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:09 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:10 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:10 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:10 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:11 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:11 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:11 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:12 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:12 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:12 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:13 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:13 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:13 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:14 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:14 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:14 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:15 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:15 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:15 WARN NetworkClient: [AdminClient clientId=adminclient-3] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:28:20 WARN TaskSetManager: Lost task 171.0 in stage 335.0 (TID 33731) (172.18.0.14 executor 1): java.lang.IllegalStateException: Error committing version 60 into HDFSStateStore[id=(op=0,part=171),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/171]\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tSuppressed: org.apache.spark.util.TaskCompletionListenerException: Could not find any valid local directory for s3ablock-0001-\n",
      "\n",
      "Previous exception in task: Error committing version 60 into HDFSStateStore[id=(op=0,part=171),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/171]\n",
      "\torg.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\torg.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\torg.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\torg.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\torg.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\torg.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\torg.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\torg.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\torg.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\torg.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\torg.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tjava.base/java.lang.Thread.run(Thread.java:840)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:254)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n",
      "\t\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n",
      "\t\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n",
      "\t\t... 9 more\n",
      "\t\tSuppressed: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\t\t\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\t\t\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\t\t\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\t\t\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:158)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2(package.scala:66)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2$adapted(package.scala:65)\n",
      "\t\t\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n",
      "\t\t\t... 12 more\n",
      "Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)\n",
      "\t... 28 more\n",
      "\n",
      "24/07/21 10:28:20 WARN TaskSetManager: Lost task 170.0 in stage 335.0 (TID 33729) (172.18.0.14 executor 1): java.lang.IllegalStateException: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.hadoop.fs.s3a.AWSS3IOException: copyFile(checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170/.60.delta.b3bba92b-6b34-4b28-af85-8062f622be0b.TID33729.tmp, checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170/60.delta) on checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170/.60.delta.b3bba92b-6b34-4b28-af85-8062f622be0b.TID33729.tmp: com.amazonaws.services.s3.model.AmazonS3Exception: Storage backend has reached its minimum free drive threshold. Please delete a few objects to proceed. (Service: Amazon S3; Status Code: 507; Error Code: XMinioStorageFull; Request ID: 17E4339B4FFC1DB9; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null), S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8:XMinioStorageFull: Storage backend has reached its minimum free drive threshold. Please delete a few objects to proceed. (Service: Amazon S3; Status Code: 507; Error Code: XMinioStorageFull; Request ID: 17E4339B4FFC1DB9; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AUtils.translateException(S3AUtils.java:320)\n",
      "\tat org.apache.hadoop.fs.s3a.Invoker.once(Invoker.java:119)\n",
      "\tat org.apache.hadoop.fs.s3a.Invoker.lambda$retry$4(Invoker.java:322)\n",
      "\tat org.apache.hadoop.fs.s3a.Invoker.retryUntranslated(Invoker.java:414)\n",
      "\tat org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:318)\n",
      "\tat org.apache.hadoop.fs.s3a.Invoker.retry(Invoker.java:293)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.copyFile(S3AFileSystem.java:4308)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.access$1200(S3AFileSystem.java:259)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem$OperationCallbacksImpl.copyFile(S3AFileSystem.java:2084)\n",
      "\tat org.apache.hadoop.fs.s3a.impl.RenameOperation.copySourceAndUpdateTracker(RenameOperation.java:638)\n",
      "\tat org.apache.hadoop.fs.s3a.impl.RenameOperation.renameFileToDest(RenameOperation.java:365)\n",
      "\tat org.apache.hadoop.fs.s3a.impl.RenameOperation.execute(RenameOperation.java:310)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerRename(S3AFileSystem.java:1999)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$rename$7(S3AFileSystem.java:1846)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.rename(S3AFileSystem.java:1844)\n",
      "\tat org.apache.hadoop.fs.FileSystem.rename(FileSystem.java:1624)\n",
      "\tat org.apache.hadoop.fs.DelegateToFileSystem.renameInternal(DelegateToFileSystem.java:206)\n",
      "\tat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:790)\n",
      "\tat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:720)\n",
      "\tat org.apache.hadoop.fs.FileContext.rename(FileContext.java:1036)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.renameTempFile(CheckpointFileManager.scala:372)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.close(CheckpointFileManager.scala:154)\n",
      "\tat net.jpountz.lz4.LZ4BlockOutputStream.close(LZ4BlockOutputStream.java:198)\n",
      "\tat java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:188)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.finalizeDeltaFile(HDFSBackedStateStoreProvider.scala:450)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.org$apache$spark$sql$execution$streaming$state$HDFSBackedStateStoreProvider$$commitUpdates(HDFSBackedStateStoreProvider.scala:320)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)\n",
      "\t... 28 more\n",
      "Caused by: com.amazonaws.services.s3.model.AmazonS3Exception: Storage backend has reached its minimum free drive threshold. Please delete a few objects to proceed. (Service: Amazon S3; Status Code: 507; Error Code: XMinioStorageFull; Request ID: 17E4339B4FFC1DB9; S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8; Proxy: null), S3 Extended Request ID: dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1879)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleServiceErrorResponse(AmazonHttpClient.java:1418)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1387)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1157)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:814)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)\n",
      "\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)\n",
      "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)\n",
      "\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)\n",
      "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5456)\n",
      "\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:5403)\n",
      "\tat com.amazonaws.services.s3.AmazonS3Client.copyObject(AmazonS3Client.java:2078)\n",
      "\tat com.amazonaws.services.s3.transfer.internal.CopyCallable.copyInOneChunk(CopyCallable.java:145)\n",
      "\tat com.amazonaws.services.s3.transfer.internal.CopyCallable.call(CopyCallable.java:133)\n",
      "\tat com.amazonaws.services.s3.transfer.internal.CopyMonitor.call(CopyMonitor.java:132)\n",
      "\tat com.amazonaws.services.s3.transfer.internal.CopyMonitor.call(CopyMonitor.java:43)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "\n",
      "24/07/21 10:28:20 WARN TaskSetManager: Lost task 172.0 in stage 335.0 (TID 33732) (172.18.0.14 executor 1): java.lang.IllegalStateException: Error committing version 60 into HDFSStateStore[id=(op=0,part=172),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/172]\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tSuppressed: org.apache.spark.util.TaskCompletionListenerException: Could not find any valid local directory for s3ablock-0001-\n",
      "\n",
      "Previous exception in task: Error committing version 60 into HDFSStateStore[id=(op=0,part=172),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/172]\n",
      "\torg.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\torg.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\torg.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\torg.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\torg.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\torg.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\torg.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\torg.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\torg.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\torg.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\torg.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tjava.base/java.lang.Thread.run(Thread.java:840)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:254)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n",
      "\t\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n",
      "\t\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n",
      "\t\t... 9 more\n",
      "\t\tSuppressed: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\t\t\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\t\t\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\t\t\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\t\t\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:158)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2(package.scala:66)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2$adapted(package.scala:65)\n",
      "\t\t\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n",
      "\t\t\t... 12 more\n",
      "Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)\n",
      "\t... 28 more\n",
      "\n",
      "24/07/21 10:28:20 ERROR TaskSetManager: Task 170 in stage 335.0 failed 4 times; aborting job\n",
      "24/07/21 10:28:20 WARN TaskSetManager: Lost task 172.3 in stage 335.0 (TID 33738) (172.18.0.14 executor 1): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 170 in stage 335.0 failed 4 times, most recent failure: Lost task 170.3 in stage 335.0 (TID 33737) (172.18.0.14 executor 1): java.lang.IllegalStateException: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tSuppressed: org.apache.spark.util.TaskCompletionListenerException: Could not find any valid local directory for s3ablock-0001-\n",
      "\n",
      "Previous exception in task: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\torg.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\torg.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\torg.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\torg.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\torg.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\torg.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\torg.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\torg.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\torg.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\torg.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\torg.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tjava.base/java.lang.Thread.run(Thread.java:840)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:254)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n",
      "\t\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n",
      "\t\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n",
      "\t\t... 9 more\n",
      "\t\tSuppressed: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\t\t\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\t\t\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\t\t\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\t\t\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:158)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2(package.scala:66)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2$adapted(package.scala:65)\n",
      "\t\t\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n",
      "\t\t\t... 12 more\n",
      "Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:)\n",
      "24/07/21 10:28:20 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 59, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@6b6aa27c] is aborting.\n",
      "24/07/21 10:28:20 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 59, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@6b6aa27c] aborted.\n",
      "24/07/21 10:28:20 WARN TaskSetManager: Lost task 149.0 in stage 335.0 (TID 33730) (172.18.0.11 executor 0): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 170 in stage 335.0 failed 4 times, most recent failure: Lost task 170.3 in stage 335.0 (TID 33737) (172.18.0.14 executor 1): java.lang.IllegalStateException: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tSuppressed: org.apache.spark.util.TaskCompletionListenerException: Could not find any valid local directory for s3ablock-0001-\n",
      "\n",
      "Previous exception in task: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\torg.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\torg.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\torg.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\torg.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\torg.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\torg.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\torg.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\torg.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\torg.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\torg.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\torg.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tjava.base/java.lang.Thread.run(Thread.java:840)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:254)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n",
      "\t\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n",
      "\t\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n",
      "\t\t... 9 more\n",
      "\t\tSuppressed: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\t\t\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\t\t\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\t\t\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\t\t\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:158)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2(package.scala:66)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2$adapted(package.scala:65)\n",
      "\t\t\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n",
      "\t\t\t... 12 more\n",
      "Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:)\n",
      "24/07/21 10:28:21 ERROR MicroBatchExecution: Query [id = f9673069-b872-4d98-96bb-aaa15a19f962, runId = d7cf1169-1232-41b0-b9c9-7c6408285f76] terminated with error\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 170 in stage 335.0 failed 4 times, most recent failure: Lost task 170.3 in stage 335.0 (TID 33737) (172.18.0.14 executor 1): java.lang.IllegalStateException: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tSuppressed: org.apache.spark.util.TaskCompletionListenerException: Could not find any valid local directory for s3ablock-0001-\n",
      "\n",
      "Previous exception in task: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\torg.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\torg.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\torg.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\torg.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\torg.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\torg.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\torg.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\torg.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\torg.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\torg.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\torg.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tjava.base/java.lang.Thread.run(Thread.java:840)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:254)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n",
      "\t\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n",
      "\t\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n",
      "\t\t... 9 more\n",
      "\t\tSuppressed: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\t\t\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\t\t\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\t\t\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\t\t\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:158)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2(package.scala:66)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2$adapted(package.scala:65)\n",
      "\t\t\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n",
      "\t\t\t... 12 more\n",
      "Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)\n",
      "\t... 28 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:318)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:741)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: java.lang.IllegalStateException: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\tat org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\tat org.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tSuppressed: org.apache.spark.util.TaskCompletionListenerException: Could not find any valid local directory for s3ablock-0001-\n",
      "\n",
      "Previous exception in task: Error committing version 60 into HDFSStateStore[id=(op=0,part=170),dir=s3a://processed-data/checkpoints/topics/OpenSeaEnrichedGlobalEvents/MarketTopCollections/state/0/170]\n",
      "\torg.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:148)\n",
      "\torg.apache.spark.sql.execution.streaming.state.StreamingAggregationStateManagerBaseImpl.commit(StreamingAggregationStateManager.scala:90)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.$anonfun$close$1(statefulOperators.scala:560)\n",
      "\tscala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\torg.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreWriter.timeTakenMs$(statefulOperators.scala:179)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec.timeTakenMs(statefulOperators.scala:467)\n",
      "\torg.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anon$1.close(statefulOperators.scala:560)\n",
      "\torg.apache.spark.util.NextIterator.closeIfNeeded(NextIterator.scala:66)\n",
      "\torg.apache.spark.util.NextIterator.hasNext(NextIterator.scala:75)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1(HashAggregateExec.scala:100)\n",
      "\torg.apache.spark.sql.execution.aggregate.HashAggregateExec.$anonfun$doExecute$1$adapted(HashAggregateExec.scala:97)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndex$2$adapted(RDD.scala:910)\n",
      "\torg.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\torg.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\torg.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\torg.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\torg.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\torg.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\torg.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\torg.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\torg.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tjava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tjava.base/java.lang.Thread.run(Thread.java:840)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:254)\n",
      "\t\tat org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)\n",
      "\t\tat org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)\n",
      "\t\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:177)\n",
      "\t\t... 9 more\n",
      "\t\tSuppressed: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\t\t\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\t\t\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\t\t\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\t\t\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\t\t\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\t\t\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\t\t\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\t\t\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.abort(HDFSBackedStateStoreProvider.scala:158)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2(package.scala:66)\n",
      "\t\t\tat org.apache.spark.sql.execution.streaming.state.package$StateStoreOps.$anonfun$mapPartitionsWithStateStore$2$adapted(package.scala:65)\n",
      "\t\t\tat org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:137)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)\n",
      "\t\t\tat org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)\n",
      "\t\t\t... 12 more\n",
      "Caused by: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for s3ablock-0001-\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:462)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:165)\n",
      "\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:146)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.createTmpFileForWrite(S3AFileSystem.java:1282)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ADataBlocks$DiskBlockFactory.create(S3ADataBlocks.java:816)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.createBlockIfNeeded(S3ABlockOutputStream.java:211)\n",
      "\tat org.apache.hadoop.fs.s3a.S3ABlockOutputStream.<init>(S3ABlockOutputStream.java:188)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.innerCreateFile(S3AFileSystem.java:1727)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$create$6(S3AFileSystem.java:1646)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)\n",
      "\tat org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)\n",
      "\tat org.apache.hadoop.fs.s3a.S3AFileSystem.create(S3AFileSystem.java:1645)\n",
      "\tat org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1305)\n",
      "\tat org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102)\n",
      "\tat org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701)\n",
      "\tat org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697)\n",
      "\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n",
      "\tat org.apache.hadoop.fs.FileContext.create(FileContext.java:703)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createTempFile(CheckpointFileManager.scala:361)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:140)\n",
      "\tat org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream.<init>(CheckpointFileManager.scala:143)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager.createAtomic(CheckpointFileManager.scala:367)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream$lzycompute(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.deltaFileStream(HDFSBackedStateStoreProvider.scala:110)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream$lzycompute(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.compressedStream(HDFSBackedStateStoreProvider.scala:111)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider$HDFSBackedStateStore.commit(HDFSBackedStateStoreProvider.scala:141)\n",
      "\t... 28 more\n",
      "24/07/21 10:30:40 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka: Name or service not known\n",
      "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
      "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:41 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:41 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:42 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:43 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:44 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:46 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:47 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:48 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:49 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:50 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka: Name or service not known\n",
      "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
      "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:51 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:52 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:53 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:54 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:55 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:56 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:57 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:58 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:30:59 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:00 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka: Name or service not known\n",
      "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
      "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:01 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:02 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:03 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:04 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:05 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:06 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:07 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:08 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:09 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:10 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:10 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka: Name or service not known\n",
      "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
      "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:11 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:11 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:12 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:12 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:13 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:13 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:14 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:14 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:15 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:15 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:16 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:16 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:16 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:17 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:18 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:18 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:18 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:19 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:19 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:20 WARN TaskSetManager: Lost task 0.0 in stage 336.0 (TID 33739) (172.18.0.14 executor 1): org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition OpenSeaRawEvents-0 could be determined\n",
      "\n",
      "24/07/21 10:31:20 WARN NetworkClient: [AdminClient clientId=adminclient-1] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka: Name or service not known\n",
      "\tat java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n",
      "\tat java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)\n",
      "\tat java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)\n",
      "\tat java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:20 WARN NetworkClient: [AdminClient clientId=adminclient-2] Error connecting to node kafka:19092 (id: 1 rack: null)\n",
      "java.net.UnknownHostException: kafka\n",
      "\tat java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)\n",
      "\tat java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)\n",
      "\tat java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)\n",
      "\tat org.apache.kafka.clients.DefaultHostResolver.resolve(DefaultHostResolver.java:27)\n",
      "\tat org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:510)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:467)\n",
      "\tat org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:173)\n",
      "\tat org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:990)\n",
      "\tat org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:301)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.sendEligibleCalls(KafkaAdminClient.java:1141)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.processRequests(KafkaAdminClient.java:1401)\n",
      "\tat org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1344)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/21 10:31:20 WARN TaskSetManager: Lost task 0.1 in stage 336.0 (TID 33741) (172.18.0.14 executor 1): org.apache.kafka.common.KafkaException: Failed to construct kafka consumer\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:830)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:665)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:613)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.createConsumer(KafkaDataConsumer.scala:124)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.<init>(KafkaDataConsumer.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:207)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:202)\n",
      "\tat org.apache.commons.pool2.BaseKeyedPooledObjectFactory.makeObject(BaseKeyedPooledObjectFactory.java:82)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.create(GenericKeyedObjectPool.java:780)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:439)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:350)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool.borrowObject(InternalKafkaConsumerPool.scala:85)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$retrieveConsumer$1(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.timeNanos(KafkaDataConsumer.scala:666)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.retrieveConsumer(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.getOrRetrieveConsumer(KafkaDataConsumer.scala:588)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$get$1(KafkaDataConsumer.scala:303)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.runUninterruptiblyIfPossible(KafkaDataConsumer.scala:656)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.get(KafkaDataConsumer.scala:299)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaBatchPartitionReader.next(KafkaBatchPartitionReader.scala:79)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:120)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:158)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1$adapted(DataSourceRDD.scala:63)\n",
      "\tat scala.Option.exists(Option.scala:376)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.advanceToNextIter(DataSourceRDD.scala:97)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:731)\n",
      "\t... 57 more\n",
      "\n",
      "24/07/21 10:31:20 ERROR TaskSetManager: Task 0 in stage 336.0 failed 4 times; aborting job\n",
      "24/07/21 10:31:21 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 111, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@44153798] is aborting.\n",
      "24/07/21 10:31:21 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 111, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@44153798] aborted.\n",
      "24/07/21 10:31:21 ERROR MicroBatchExecution: Query [id = 9ff69ff7-1452-4acb-8835-04af2c1c7326, runId = b768864b-8a30-4c74-a68e-2b3437c528d9] terminated with error\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 336.0 failed 4 times, most recent failure: Lost task 0.3 in stage 336.0 (TID 33743) (172.18.0.14 executor 1): org.apache.kafka.common.KafkaException: Failed to construct kafka consumer\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:830)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:665)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:613)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.createConsumer(KafkaDataConsumer.scala:124)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.<init>(KafkaDataConsumer.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:207)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:202)\n",
      "\tat org.apache.commons.pool2.BaseKeyedPooledObjectFactory.makeObject(BaseKeyedPooledObjectFactory.java:82)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.create(GenericKeyedObjectPool.java:780)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:439)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:350)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool.borrowObject(InternalKafkaConsumerPool.scala:85)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$retrieveConsumer$1(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.timeNanos(KafkaDataConsumer.scala:666)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.retrieveConsumer(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.getOrRetrieveConsumer(KafkaDataConsumer.scala:588)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$get$1(KafkaDataConsumer.scala:303)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.runUninterruptiblyIfPossible(KafkaDataConsumer.scala:656)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.get(KafkaDataConsumer.scala:299)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaBatchPartitionReader.next(KafkaBatchPartitionReader.scala:79)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:120)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:158)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1$adapted(DataSourceRDD.scala:63)\n",
      "\tat scala.Option.exists(Option.scala:376)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.advanceToNextIter(DataSourceRDD.scala:97)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:731)\n",
      "\t... 57 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:318)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:741)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: org.apache.kafka.common.KafkaException: Failed to construct kafka consumer\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:830)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:665)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:613)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.createConsumer(KafkaDataConsumer.scala:124)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.<init>(KafkaDataConsumer.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:207)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:202)\n",
      "\tat org.apache.commons.pool2.BaseKeyedPooledObjectFactory.makeObject(BaseKeyedPooledObjectFactory.java:82)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.create(GenericKeyedObjectPool.java:780)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:439)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:350)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool.borrowObject(InternalKafkaConsumerPool.scala:85)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$retrieveConsumer$1(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.timeNanos(KafkaDataConsumer.scala:666)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.retrieveConsumer(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.getOrRetrieveConsumer(KafkaDataConsumer.scala:588)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$get$1(KafkaDataConsumer.scala:303)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.runUninterruptiblyIfPossible(KafkaDataConsumer.scala:656)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.get(KafkaDataConsumer.scala:299)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaBatchPartitionReader.next(KafkaBatchPartitionReader.scala:79)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:120)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:158)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1$adapted(DataSourceRDD.scala:63)\n",
      "\tat scala.Option.exists(Option.scala:376)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.advanceToNextIter(DataSourceRDD.scala:97)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:731)\n",
      "\t... 57 more\n",
      "24/07/21 10:31:21 WARN TaskSetManager: Lost task 0.0 in stage 338.0 (TID 33740) (172.18.0.11 executor 0): org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition OpenSeaRawEvents-0 could be determined\n",
      "\n",
      "24/07/21 10:31:21 WARN TaskSetManager: Lost task 0.1 in stage 338.0 (TID 33744) (172.18.0.11 executor 0): org.apache.kafka.common.KafkaException: Failed to construct kafka consumer\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:830)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:665)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:613)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.createConsumer(KafkaDataConsumer.scala:124)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.<init>(KafkaDataConsumer.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:207)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:202)\n",
      "\tat org.apache.commons.pool2.BaseKeyedPooledObjectFactory.makeObject(BaseKeyedPooledObjectFactory.java:82)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.create(GenericKeyedObjectPool.java:780)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:439)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:350)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool.borrowObject(InternalKafkaConsumerPool.scala:85)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$retrieveConsumer$1(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.timeNanos(KafkaDataConsumer.scala:666)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.retrieveConsumer(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.getOrRetrieveConsumer(KafkaDataConsumer.scala:588)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$get$1(KafkaDataConsumer.scala:303)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.runUninterruptiblyIfPossible(KafkaDataConsumer.scala:656)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.get(KafkaDataConsumer.scala:299)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaBatchPartitionReader.next(KafkaBatchPartitionReader.scala:79)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:120)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:158)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1$adapted(DataSourceRDD.scala:63)\n",
      "\tat scala.Option.exists(Option.scala:376)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.advanceToNextIter(DataSourceRDD.scala:97)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:731)\n",
      "\t... 55 more\n",
      "\n",
      "24/07/21 10:31:21 ERROR TaskSetManager: Task 0 in stage 338.0 failed 4 times; aborting job\n",
      "24/07/21 10:31:21 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 60, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@5680a819] is aborting.\n",
      "24/07/21 10:31:21 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 60, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@5680a819] aborted.\n",
      "24/07/21 10:31:21 ERROR MicroBatchExecution: Query [id = 5a60f7fd-5e79-4695-979b-c6f6f406602d, runId = d447588e-ab4b-4dda-8086-ef770e553848] terminated with error\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 338.0 failed 4 times, most recent failure: Lost task 0.3 in stage 338.0 (TID 33746) (172.18.0.11 executor 0): org.apache.kafka.common.KafkaException: Failed to construct kafka consumer\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:830)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:665)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:613)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.createConsumer(KafkaDataConsumer.scala:124)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.<init>(KafkaDataConsumer.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:207)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:202)\n",
      "\tat org.apache.commons.pool2.BaseKeyedPooledObjectFactory.makeObject(BaseKeyedPooledObjectFactory.java:82)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.create(GenericKeyedObjectPool.java:780)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:439)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:350)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool.borrowObject(InternalKafkaConsumerPool.scala:85)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$retrieveConsumer$1(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.timeNanos(KafkaDataConsumer.scala:666)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.retrieveConsumer(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.getOrRetrieveConsumer(KafkaDataConsumer.scala:588)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$get$1(KafkaDataConsumer.scala:303)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.runUninterruptiblyIfPossible(KafkaDataConsumer.scala:656)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.get(KafkaDataConsumer.scala:299)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaBatchPartitionReader.next(KafkaBatchPartitionReader.scala:79)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:120)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:158)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1$adapted(DataSourceRDD.scala:63)\n",
      "\tat scala.Option.exists(Option.scala:376)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.advanceToNextIter(DataSourceRDD.scala:97)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:731)\n",
      "\t... 55 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:318)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:741)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: org.apache.kafka.common.KafkaException: Failed to construct kafka consumer\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:830)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:665)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:613)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.createConsumer(KafkaDataConsumer.scala:124)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumer.<init>(KafkaDataConsumer.scala:61)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:207)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool$ObjectFactory.create(InternalKafkaConsumerPool.scala:202)\n",
      "\tat org.apache.commons.pool2.BaseKeyedPooledObjectFactory.makeObject(BaseKeyedPooledObjectFactory.java:82)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.create(GenericKeyedObjectPool.java:780)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:439)\n",
      "\tat org.apache.commons.pool2.impl.GenericKeyedObjectPool.borrowObject(GenericKeyedObjectPool.java:350)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.InternalKafkaConsumerPool.borrowObject(InternalKafkaConsumerPool.scala:85)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$retrieveConsumer$1(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.timeNanos(KafkaDataConsumer.scala:666)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.retrieveConsumer(KafkaDataConsumer.scala:604)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.getOrRetrieveConsumer(KafkaDataConsumer.scala:588)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.$anonfun$get$1(KafkaDataConsumer.scala:303)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.runUninterruptiblyIfPossible(KafkaDataConsumer.scala:656)\n",
      "\tat org.apache.spark.sql.kafka010.consumer.KafkaDataConsumer.get(KafkaDataConsumer.scala:299)\n",
      "\tat org.apache.spark.sql.kafka010.KafkaBatchPartitionReader.next(KafkaBatchPartitionReader.scala:79)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.PartitionIterator.hasNext(DataSourceRDD.scala:120)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.MetricsIterator.hasNext(DataSourceRDD.scala:158)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.$anonfun$hasNext$1$adapted(DataSourceRDD.scala:63)\n",
      "\tat scala.Option.exists(Option.scala:376)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.advanceToNextIter(DataSourceRDD.scala:97)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataSourceRDD$$anon$1.hasNext(DataSourceRDD.scala:63)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.hashAgg_doAggregateWithKeys_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:89)\n",
      "\tat org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:48)\n",
      "\tat org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:731)\n",
      "\t... 55 more\n"
     ]
    }
   ],
   "source": [
    "# Send events to Kafka Topic\n",
    "top_collections_query = (\n",
    "    top_collections_windowed_events.select(F.to_json(F.struct(\"*\")).alias(\"value\"))\n",
    "    .writeStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:19092\")\n",
    "    .option(\n",
    "        \"checkpointLocation\",\n",
    "        query_checkpoint_folder,\n",
    "    )\n",
    "    .option(\"topic\", kafka_topic)\n",
    ")\n",
    "top_collections_query.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:========>      (109 + 1) / 200][Stage 9:>                (0 + 0) / 200]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/20 19:08:09 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-62dfe34c-5490-4f92-acf0-690ed3b14b17. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/07/20 19:08:09 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "24/07/20 19:08:10 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "[Stage 7:========>      (111 + 1) / 200][Stage 9:>                (0 + 0) / 200]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0xffff94264c90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For debugging:\n",
    "top_collections_query_console = (\n",
    "    top_collections_windowed_events.select(F.to_json(F.struct(\"*\")).alias(\"value\"))\n",
    "    .writeStream.format(\"console\")\n",
    "    .option(\"truncate\", False)\n",
    ")\n",
    "top_collections_query_console.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (465368463.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 35\u001b[0;36m\u001b[0m\n\u001b[0;31m    F.lit(\"\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/20 19:08:10 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                 (0 + 1) / 1][Stage 18:>                 (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/20 19:18:27 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 4, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@1574cd1a] is aborting.\n",
      "24/07/20 19:18:27 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 4, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@1574cd1a] aborted.\n",
      "24/07/20 19:18:27 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=false]] is aborting.\n",
      "24/07/20 19:18:27 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 55, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@2ac72f2] is aborting.\n",
      "24/07/20 19:18:27 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 55, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@2ac72f2] aborted.\n",
      "24/07/20 19:18:27 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 4, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@1d3145cb] is aborting.\n",
      "24/07/20 19:18:27 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 4, writer: org.apache.spark.sql.kafka010.KafkaStreamingWrite@1d3145cb] aborted.\n",
      "24/07/20 19:18:27 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 4, writer: ConsoleWriter[numRows=20, truncate=false]] aborted.\n",
      "24/07/20 19:18:27 ERROR MicroBatchExecution: Query [id = 105d4aa6-b3e1-4398-bcde-1ad6aea70092, runId = ef8ef0ba-661f-4b58-8b91-78561ff5c176] terminated with error\n",
      "org.apache.spark.SparkException: Job 22 cancelled because SparkContext was shut down\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1253)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1251)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1251)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:3087)\n",
      "\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$3(DAGScheduler.scala:2973)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2973)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2216)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:686)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:318)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:741)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "24/07/20 19:18:27 ERROR MicroBatchExecution: Query [id = 9ff69ff7-1452-4acb-8835-04af2c1c7326, runId = 6193eff6-c550-465c-b57c-d740f8541aab] terminated with error\n",
      "org.apache.spark.SparkException: Job 19 cancelled because SparkContext was shut down\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1253)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1251)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1251)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:3087)\n",
      "\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$3(DAGScheduler.scala:2973)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2973)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2216)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:686)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:318)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:741)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "24/07/20 19:18:27 ERROR MicroBatchExecution: Query [id = 5a60f7fd-5e79-4695-979b-c6f6f406602d, runId = 45361cdf-99be-4593-99ba-20dd3ab15bac] terminated with error\n",
      "org.apache.spark.SparkException: Job 20 cancelled because SparkContext was shut down\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1253)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1251)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1251)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:3087)\n",
      "\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$3(DAGScheduler.scala:2973)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2973)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2216)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:686)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:318)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:741)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "24/07/20 19:18:27 ERROR MicroBatchExecution: Query [id = f9673069-b872-4d98-96bb-aaa15a19f962, runId = 717a3290-7e9e-43a8-ba83-ec21498212d5] terminated with error\n",
      "org.apache.spark.SparkException: Job 21 cancelled because SparkContext was shut down\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1253)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1251)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1251)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:3087)\n",
      "\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$3(DAGScheduler.scala:2973)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2973)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2263)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2216)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:686)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:318)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:741)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "24/07/20 19:18:27 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() for one-way message.\n",
      "org.apache.spark.SparkException: Could not find CoarseGrainedScheduler.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:178)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postOneWayMessage(Dispatcher.scala:150)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcHandler.receive(NettyRpcEnv.scala:690)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.processOneWayMessage(TransportRequestHandler.java:274)\n",
      "\tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:111)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:140)\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)\n",
      "\tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:442)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n",
      "\tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "# Read data from the topic as a DataFrame.\n",
    "raw_topic_df = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:19092\")\n",
    "    .option(\"subscribe\", \"OpenSeaRawEvents\")\n",
    "    .load()\n",
    ")\n",
    "raw_topic_df.printSchema()\n",
    "parsed_df = raw_topic_df.selectExpr(\n",
    "    \"CAST(value as string) as json_value\",\n",
    "    \"timestamp as processed_at\",\n",
    ")\n",
    "nft_data = parsed_df.selectExpr(\n",
    "    \"get_json_object(json_value, '$.payload.payload.collection.slug') as collection_slug\",\n",
    "    \"to_timestamp(get_json_object(json_value, '$.payload.sent_at')) as sent_at\",\n",
    ")\n",
    "agg_df = (\n",
    "    nft_data.withWatermark(\n",
    "        \"sent_at\", \"30 seconds\"\n",
    "    )  # Define watermark to handle late data. ie, Data that arrives after 30 seconds of the event time will be ignored\n",
    "    .groupBy(\n",
    "        F.window(\n",
    "            # Every 30 seconds calculate the count of events in the last 1 minute\n",
    "            \"sent_at\",\n",
    "            \"1 minute\",\n",
    "            \"30 seconds\",\n",
    "        ),\n",
    "        \"collection_slug\",\n",
    "    )\n",
    "    .count()\n",
    ")\n",
    "agg_df = agg_df.select(\n",
    "    F.col(\"window.start\").alias(\"window_start\"),\n",
    "    F.col(\"window.end\").alias(\"window_end\"),\n",
    "    F.lit(\"\")\n",
    "    \"collection_slug\",\n",
    "    \"count\",\n",
    ")\n",
    "agg_df.printSchema()\n",
    "# query = agg_df.writeStream.format(\"console\").outputMode(\"complete\")\n",
    "# query.start().awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging the query\n",
    "quert = agg_df.writeStream.format(\"console\").outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Start the Structured Streaming query to Kafka\n",
    "query = agg_df.select(F.to_json(F.struct(\"*\")).alias(\"value\"))\n",
    "query.printSchema()\n",
    "query = (\n",
    "    query\n",
    "    .writeStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:19092\")\n",
    "    .option(\n",
    "        \"checkpointLocation\",\n",
    "        \"s3a://processed-data/checkpoints/topics/OpenSeaEnrichedEvents/\",\n",
    "    )\n",
    "    .option(\"topic\", \"OpenSeaEnrichedEvents\")\n",
    ")\n",
    "query.start().awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
