{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142d521d-0930-4226-9b98-da5b4d7ff50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable horizontal scrolling:\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c242bae3-e3d4-418d-91eb-4c6ae00e5c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /tmp/.ivy/cache\n",
      "The jars for the packages stored in: /tmp/.ivy/jars\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ad3d458c-80d8-4ea0-9ff2-fb6e0206f8a7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.5.0 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 1125ms :: artifacts dl 23ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.5.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   13  |   0   |   0   |   0   ||   13  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ad3d458c-80d8-4ea0-9ff2-fb6e0206f8a7\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 13 already retrieved (0kB/16ms)\n",
      "24/07/23 19:56:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/hadoop-aws-3.3.2.jar does not exist, skipping.\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/aws-java-sdk-1.12.367.jar does not exist, skipping.\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/s3-2.18.41.jar does not exist, skipping.\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/aws-java-sdk-bundle-1.11.1026.jar does not exist, skipping.\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/spark-streaming-kafka-0-10-assembly_2.12-3.5.0.jar does not exist, skipping.\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/spark-sql-kafka-0-10_2.12-3.5.0.jar does not exist, skipping.\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/avro-mapred-1.11.2.jar does not exist, skipping.\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/avro-ipc-1.11.2.jar does not exist, skipping.\n",
      "24/07/23 19:56:53 WARN DependencyUtils: Local jar /workdir/jars/avro-1.11.2.jar does not exist, skipping.\n",
      "24/07/23 19:56:54 INFO SparkContext: Running Spark version 3.5.1\n",
      "24/07/23 19:56:54 INFO SparkContext: OS info Linux, 6.6.31-linuxkit, aarch64\n",
      "24/07/23 19:56:54 INFO SparkContext: Java version 17.0.11\n",
      "24/07/23 19:56:54 INFO ResourceUtils: ==============================================================\n",
      "24/07/23 19:56:54 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "24/07/23 19:56:54 INFO ResourceUtils: ==============================================================\n",
      "24/07/23 19:56:54 INFO SparkContext: Submitted application: Batch\n",
      "24/07/23 19:56:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "24/07/23 19:56:54 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor\n",
      "24/07/23 19:56:54 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "24/07/23 19:56:54 INFO SecurityManager: Changing view acls to: root,spark\n",
      "24/07/23 19:56:54 INFO SecurityManager: Changing modify acls to: root,spark\n",
      "24/07/23 19:56:54 INFO SecurityManager: Changing view acls groups to: \n",
      "24/07/23 19:56:54 INFO SecurityManager: Changing modify acls groups to: \n",
      "24/07/23 19:56:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY\n",
      "24/07/23 19:56:54 INFO Utils: Successfully started service 'sparkDriver' on port 34397.\n",
      "24/07/23 19:56:54 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/07/23 19:56:54 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/07/23 19:56:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "24/07/23 19:56:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "24/07/23 19:56:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/07/23 19:56:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5eaeee11-34c2-4951-b3ac-5b6c78d1d63d\n",
      "24/07/23 19:56:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
      "24/07/23 19:56:55 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "24/07/23 19:56:55 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "24/07/23 19:56:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/hadoop-aws-3.3.2.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/hadoop-aws-3.3.2.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/aws-java-sdk-1.12.367.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/aws-java-sdk-1.12.367.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/s3-2.18.41.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/s3-2.18.41.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/aws-java-sdk-bundle-1.11.1026.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/aws-java-sdk-bundle-1.11.1026.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/spark-streaming-kafka-0-10-assembly_2.12-3.5.0.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/spark-streaming-kafka-0-10-assembly_2.12-3.5.0.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/spark-sql-kafka-0-10_2.12-3.5.0.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/spark-sql-kafka-0-10_2.12-3.5.0.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/avro-mapred-1.11.2.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/avro-mapred-1.11.2.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/avro-ipc-1.11.2.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/avro-ipc-1.11.2.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 ERROR SparkContext: Failed to add file:/workdir/jars/avro-1.11.2.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /workdir/jars/avro-1.11.2.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2100)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2156)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:526)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:526)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:526)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://e15ec367706a:34397/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://e15ec367706a:34397/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.tukaani_xz-1.9.jar at spark://e15ec367706a:34397/jars/org.tukaani_xz-1.9.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://e15ec367706a:34397/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://e15ec367706a:34397/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://e15ec367706a:34397/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://e15ec367706a:34397/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://e15ec367706a:34397/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.lz4_lz4-java-1.8.0.jar at spark://e15ec367706a:34397/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://e15ec367706a:34397/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://e15ec367706a:34397/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://e15ec367706a:34397/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added JAR file:///tmp/.ivy/jars/commons-logging_commons-logging-1.1.3.jar at spark://e15ec367706a:34397/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar at spark://e15ec367706a:34397/files/org.apache.spark_spark-avro_2.12-3.5.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.apache.spark_spark-avro_2.12-3.5.0.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.apache.spark_spark-avro_2.12-3.5.0.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://e15ec367706a:34397/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.tukaani_xz-1.9.jar at spark://e15ec367706a:34397/files/org.tukaani_xz-1.9.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.tukaani_xz-1.9.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.tukaani_xz-1.9.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://e15ec367706a:34397/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://e15ec367706a:34397/files/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.apache.kafka_kafka-clients-3.4.1.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://e15ec367706a:34397/files/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/com.google.code.findbugs_jsr305-3.0.0.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://e15ec367706a:34397/files/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.apache.commons_commons-pool2-2.11.1.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://e15ec367706a:34397/files/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.lz4_lz4-java-1.8.0.jar at spark://e15ec367706a:34397/files/org.lz4_lz4-java-1.8.0.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.lz4_lz4-java-1.8.0.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://e15ec367706a:34397/files/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.xerial.snappy_snappy-java-1.1.10.3.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://e15ec367706a:34397/files/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.slf4j_slf4j-api-2.0.7.jar\n",
      "24/07/23 19:56:55 INFO SparkContext: Added file file:///tmp/.ivy/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://e15ec367706a:34397/files/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:55 INFO Utils: Copying /tmp/.ivy/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/org.apache.hadoop_hadoop-client-api-3.3.4.jar\n",
      "24/07/23 19:56:56 INFO SparkContext: Added file file:///tmp/.ivy/jars/commons-logging_commons-logging-1.1.3.jar at spark://e15ec367706a:34397/files/commons-logging_commons-logging-1.1.3.jar with timestamp 1721764614363\n",
      "24/07/23 19:56:56 INFO Utils: Copying /tmp/.ivy/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-0400043c-bbda-4321-9ae6-2ef5d28bdb46/userFiles-a71a6b35-f659-4fa7-adb7-4d806ac83067/commons-logging_commons-logging-1.1.3.jar\n",
      "24/07/23 19:56:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark:7077...\n",
      "24/07/23 19:56:56 INFO TransportClientFactory: Successfully created connection to spark/172.21.0.11:7077 after 56 ms (0 ms spent in bootstraps)\n",
      "24/07/23 19:56:56 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240723195656-0001\n",
      "24/07/23 19:56:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240723195656-0001/0 on worker-20240723193702-172.21.0.18-33497 (172.21.0.18:33497) with 1 core(s)\n",
      "24/07/23 19:56:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20240723195656-0001/0 on hostPort 172.21.0.18:33497 with 1 core(s), 1024.0 MiB RAM\n",
      "24/07/23 19:56:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240723195656-0001/1 on worker-20240723193702-172.21.0.21-45425 (172.21.0.21:45425) with 1 core(s)\n",
      "24/07/23 19:56:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20240723195656-0001/1 on hostPort 172.21.0.21:45425 with 1 core(s), 1024.0 MiB RAM\n",
      "24/07/23 19:56:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34885.\n",
      "24/07/23 19:56:56 INFO NettyBlockTransferService: Server created on e15ec367706a:34885\n",
      "24/07/23 19:56:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "24/07/23 19:56:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e15ec367706a, 34885, None)\n",
      "24/07/23 19:56:56 INFO BlockManagerMasterEndpoint: Registering block manager e15ec367706a:34885 with 434.4 MiB RAM, BlockManagerId(driver, e15ec367706a, 34885, None)\n",
      "24/07/23 19:56:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, e15ec367706a, 34885, None)\n",
      "24/07/23 19:56:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, e15ec367706a, 34885, None)\n",
      "24/07/23 19:56:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240723195656-0001/1 is now RUNNING\n",
      "24/07/23 19:56:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240723195656-0001/0 is now RUNNING\n",
      "24/07/23 19:56:57 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://e15ec367706a:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Batch</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffffa43cb350>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Batch\")  # type: ignore\n",
    "    .master(\"spark://spark:7077\")\n",
    "    .config(\"spark.executor.cores\", 1)\n",
    "    .config(\"spark.executor.instances\", 1)\n",
    "    .config(\"spark.cores.max\", 2)\n",
    "    # Set configuration for Notebook display\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    # Log level to WARN to avoid huge logs\n",
    "    .config(\"spark.logConf\", False)\n",
    "    .getOrCreate()\n",
    ")\n",
    "# spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ce971e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/23 19:57:00 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>event</th><th>payload</th><th>ref</th><th>topic</th></tr>\n",
       "<tr><td>item_metadata_upd...</td><td>{item_metadata_up...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_metadata_upd...</td><td>{item_metadata_up...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_metadata_upd...</td><td>{item_metadata_up...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_metadata_upd...</td><td>{item_metadata_up...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>phx_reply</td><td>{NULL, NULL, NULL...</td><td>0</td><td>phoenix</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_metadata_upd...</td><td>{item_metadata_up...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_metadata_upd...</td><td>{item_metadata_up...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_metadata_upd...</td><td>{item_metadata_up...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "<tr><td>item_transferred</td><td>{item_transferred...</td><td>NULL</td><td>collection:*</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+--------------------+----+------------+\n",
       "|               event|             payload| ref|       topic|\n",
       "+--------------------+--------------------+----+------------+\n",
       "|item_metadata_upd...|{item_metadata_up...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|item_metadata_upd...|{item_metadata_up...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|item_metadata_upd...|{item_metadata_up...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|item_metadata_upd...|{item_metadata_up...|NULL|collection:*|\n",
       "|           phx_reply|{NULL, NULL, NULL...|   0|     phoenix|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|item_metadata_upd...|{item_metadata_up...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "|item_metadata_upd...|{item_metadata_up...|NULL|collection:*|\n",
       "|item_metadata_upd...|{item_metadata_up...|NULL|collection:*|\n",
       "|    item_transferred|{item_transferred...|NULL|collection:*|\n",
       "+--------------------+--------------------+----+------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.json(\"s3a://raw-data/topics/OpenSeaRawEvents/year=*/month=*/day=*/hour=*/*.json.gz\")\n",
    "# print(\"Count: \", df.count())\n",
    "# print(\"Partitions: \", df.rdd.getNumPartitions())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39774803-156e-442a-8252-12c1caf47e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event: string (nullable = true)\n",
      " |-- payload: struct (nullable = true)\n",
      " |    |-- event_type: string (nullable = true)\n",
      " |    |-- payload: struct (nullable = true)\n",
      " |    |    |-- chain: string (nullable = true)\n",
      " |    |    |-- collection: struct (nullable = true)\n",
      " |    |    |    |-- slug: string (nullable = true)\n",
      " |    |    |-- event_timestamp: string (nullable = true)\n",
      " |    |    |-- from_account: struct (nullable = true)\n",
      " |    |    |    |-- address: string (nullable = true)\n",
      " |    |    |-- item: struct (nullable = true)\n",
      " |    |    |    |-- chain: struct (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- metadata: struct (nullable = true)\n",
      " |    |    |    |    |-- animation_url: string (nullable = true)\n",
      " |    |    |    |    |-- background_color: string (nullable = true)\n",
      " |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |-- image_url: string (nullable = true)\n",
      " |    |    |    |    |-- metadata_url: string (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- traits: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- display_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- max_value: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- order: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- trait_count: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- trait_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- value: string (nullable = true)\n",
      " |    |    |    |-- nft_id: string (nullable = true)\n",
      " |    |    |    |-- permalink: string (nullable = true)\n",
      " |    |    |-- quantity: long (nullable = true)\n",
      " |    |    |-- to_account: struct (nullable = true)\n",
      " |    |    |    |-- address: string (nullable = true)\n",
      " |    |    |-- transaction: struct (nullable = true)\n",
      " |    |    |    |-- hash: string (nullable = true)\n",
      " |    |    |    |-- timestamp: string (nullable = true)\n",
      " |    |-- sent_at: string (nullable = true)\n",
      " |    |-- status: string (nullable = true)\n",
      " |-- ref: long (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.describe().show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7949c5e-dc4f-4246-9f3a-a56778ad6e68",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[FIELD_NOT_FOUND] No such struct field `payment_token` in `chain`, `collection`, `event_timestamp`, `from_account`, `item`, `quantity`, `to_account`, `transaction`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m functions \u001b[39mas\u001b[39;00m F\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m types \u001b[39mas\u001b[39;00m T\n\u001b[0;32m----> 4\u001b[0m df_events \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mselect(\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mevent\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.event_type\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mevent_type\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      7\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.collection.slug\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mcollection_slug\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      8\u001b[0m     F\u001b[39m.\u001b[39;49mto_timestamp(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.sent_at\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39msent_at\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      9\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.status\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mstatus\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     10\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.item.metadata.name\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mitem_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     11\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.item.permalink\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mitem_url\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     12\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.item.nft_id\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mitem_nft_id\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     13\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.item.metadata.image_url\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mimage_url\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     14\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.item.chain.name\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mitem_blockchain\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     15\u001b[0m     \u001b[39m# F.to_timestamp(F.col(\"payload.payload.listing_date\")).alias(\"listing_date\"),\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39m# F.col(\"payload.payload.listing_type\").alias(\"listing_type\"),\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.from_account.address\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mfrom_account\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     18\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.to_account.address\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mto_account\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     19\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.payment_token.symbol\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mpayment_symbol\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     20\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.payment_token.eth_price\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mcast(T\u001b[39m.\u001b[39;49mDoubleType())\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39meth_price\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     21\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.payment_token.usd_price\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mcast(T\u001b[39m.\u001b[39;49mDoubleType())\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39musd_price\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     22\u001b[0m     F\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mpayload.payload.quantity\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mcast(T\u001b[39m.\u001b[39;49mIntegerType())\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mquantity\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     23\u001b[0m )\u001b[39m.\u001b[39mfilter(F\u001b[39m.\u001b[39mcol(\u001b[39m\"\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mphx_reply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m df_events\u001b[39m.\u001b[39mcache()\n\u001b[1;32m     25\u001b[0m df_events\u001b[39m.\u001b[39mshow(truncate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/dataframe.py:3227\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcols: \u001b[39m\"\u001b[39m\u001b[39mColumnOrName\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \n\u001b[1;32m   3185\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[39m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3226\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3227\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mselect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jcols(\u001b[39m*\u001b[39;49mcols))\n\u001b[1;32m   3228\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [FIELD_NOT_FOUND] No such struct field `payment_token` in `chain`, `collection`, `event_timestamp`, `from_account`, `item`, `quantity`, `to_account`, `transaction`."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "df_events = df.select(\n",
    "    \"event\",\n",
    "    F.col(\"payload.event_type\").alias(\"event_type\"),\n",
    "    F.col(\"payload.payload.collection.slug\").alias(\"collection_slug\"),\n",
    "    F.to_timestamp(\"payload.sent_at\").alias(\"sent_at\"),\n",
    "    F.col(\"payload.status\").alias(\"status\"),\n",
    "    F.col(\"payload.payload.item.metadata.name\").alias(\"item_name\"),\n",
    "    F.col(\"payload.payload.item.permalink\").alias(\"item_url\"),\n",
    "    F.col(\"payload.payload.item.nft_id\").alias(\"item_nft_id\"),\n",
    "    F.col(\"payload.payload.item.metadata.image_url\").alias(\"image_url\"),\n",
    "    F.col(\"payload.payload.item.chain.name\").alias(\"item_blockchain\"),\n",
    "    F.to_timestamp(F.col(\"payload.payload.listing_date\")).alias(\"listing_date\"),\n",
    "    F.col(\"payload.payload.listing_type\").alias(\"listing_type\"),\n",
    "    F.col(\"payload.payload.from_account.address\").alias(\"from_account\"),\n",
    "    F.col(\"payload.payload.to_account.address\").alias(\"to_account\"),\n",
    "    F.col(\"payload.payload.payment_token.symbol\").alias(\"payment_symbol\"),\n",
    "    F.col(\"payload.payload.payment_token.eth_price\").cast(T.DoubleType()).alias(\"eth_price\"),\n",
    "    F.col(\"payload.payload.payment_token.usd_price\").cast(T.DoubleType()).alias(\"usd_price\"),\n",
    "    F.col(\"payload.payload.quantity\").cast(T.IntegerType()).alias(\"quantity\"),\n",
    ").filter(F.col(\"event\") != \"phx_reply\")\n",
    "df_events.cache()\n",
    "df_events.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6fc59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_events' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_events\u001b[39m.\u001b[39mprintSchema()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_events' is not defined"
     ]
    }
   ],
   "source": [
    "df_events.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc52765",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:===================================================> (1158 + 1) / 1181]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+--------------------------+\n",
      "|max(sent_at)              |min(sent_at)              |\n",
      "+--------------------------+--------------------------+\n",
      "|2024-07-21 10:56:00.299731|2024-07-20 15:32:21.847767|\n",
      "+--------------------------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_events.select(F.max(\"sent_at\"), F.min(\"sent_at\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df304807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===================================================>(1178 + 1) / 1181]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|event_type           |count |\n",
      "+---------------------+------+\n",
      "|item_transferred     |104352|\n",
      "|item_metadata_updated|8259  |\n",
      "|item_listed          |5     |\n",
      "|item_cancelled       |1     |\n",
      "|item_sold            |2     |\n",
      "|order_invalidate     |2     |\n",
      "+---------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_events.groupBy(\"event_type\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:===================================================>(1046 + 1) / 1048]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|event_type |count|\n",
      "+-----------+-----+\n",
      "|item_listed|4    |\n",
      "|item_sold  |2    |\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_events.filter((F.col(\"usd_price\").isNotNull())).groupBy(\"event_type\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>event</th><th>event_type</th><th>collection_slug</th><th>sent_at</th><th>status</th><th>item_name</th><th>item_url</th><th>item_nft_id</th><th>image_url</th><th>item_blockchain</th><th>listing_date</th><th>listing_type</th><th>from_account</th><th>to_account</th><th>payment_symbol</th><th>eth_price</th><th>usd_price</th><th>quantity</th></tr>\n",
       "<tr><td>item_sold</td><td>item_sold</td><td>meta-croak-not-wi...</td><td>2024-07-20 15:41:...</td><td>NULL</td><td>Meta Croak - Not ...</td><td>https://testnets....</td><td>sepolia/0x50976f5...</td><td>https://i.seadn.i...</td><td>sepolia</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>ETH</td><td>1.000000000000000</td><td>3505.510000000000...</td><td>1</td></tr>\n",
       "<tr><td>item_sold</td><td>item_sold</td><td>cryptoverse-contract</td><td>2024-07-20 15:54:...</td><td>NULL</td><td>Blue</td><td>https://testnets....</td><td>avalanche_fuji/0x...</td><td>NULL</td><td>avalanche_fuji</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>AVAX</td><td>0.008079590000000</td><td>28.32000000000000...</td><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+--------------------+---------------+------------+------------+------------+----------+--------------+-----------------+--------------------+--------+\n",
       "|    event|event_type|     collection_slug|             sent_at|status|           item_name|            item_url|         item_nft_id|           image_url|item_blockchain|listing_date|listing_type|from_account|to_account|payment_symbol|        eth_price|           usd_price|quantity|\n",
       "+---------+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+--------------------+---------------+------------+------------+------------+----------+--------------+-----------------+--------------------+--------+\n",
       "|item_sold| item_sold|meta-croak-not-wi...|2024-07-20 15:41:...|  NULL|Meta Croak - Not ...|https://testnets....|sepolia/0x50976f5...|https://i.seadn.i...|        sepolia|        NULL|        NULL|        NULL|      NULL|           ETH|1.000000000000000|3505.510000000000...|       1|\n",
       "|item_sold| item_sold|cryptoverse-contract|2024-07-20 15:54:...|  NULL|                Blue|https://testnets....|avalanche_fuji/0x...|                NULL| avalanche_fuji|        NULL|        NULL|        NULL|      NULL|          AVAX|0.008079590000000|28.32000000000000...|       1|\n",
       "+---------+----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+--------------------+---------------+------------+------------+------------+----------+--------------+-----------------+--------------------+--------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.filter((F.col(\"event_type\") == \"item_sold\")).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb40e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>event</th><th>event_type</th><th>collection_slug</th><th>sent_at</th><th>status</th><th>item_name</th><th>item_url</th><th>item_nft_id</th><th>image_url</th><th>item_blockchain</th><th>listing_date</th><th>listing_type</th><th>from_account</th><th>to_account</th><th>payment_symbol</th><th>eth_price</th><th>usd_price</th><th>quantity</th></tr>\n",
       "<tr><td>item_listed</td><td>item_listed</td><td>meta-croak-not-wi...</td><td>2024-07-20 15:36:...</td><td>NULL</td><td>Meta Croak - Not ...</td><td>https://testnets....</td><td>sepolia/0x50976f5...</td><td>https://i.seadn.i...</td><td>sepolia</td><td>2024-07-20 15:35:57</td><td>NULL</td><td>NULL</td><td>NULL</td><td>ETH</td><td>1.0</td><td>3505.51</td><td>1</td></tr>\n",
       "<tr><td>item_listed</td><td>item_listed</td><td>cyan-bayc-2</td><td>2024-07-20 15:43:...</td><td>NULL</td><td>NULL</td><td>https://testnets....</td><td>sepolia/0x300b105...</td><td>https://i.seadn.i...</td><td>sepolia</td><td>2024-07-20 15:43:24</td><td>NULL</td><td>NULL</td><td>NULL</td><td>ETH</td><td>1.0</td><td>3505.51</td><td>1</td></tr>\n",
       "<tr><td>item_listed</td><td>item_listed</td><td>unidentified-cont...</td><td>2024-07-20 19:01:...</td><td>NULL</td><td>NULL</td><td>https://testnets....</td><td>avalanche_fuji/0x...</td><td>NULL</td><td>avalanche_fuji</td><td>2024-07-20 19:01:04</td><td>NULL</td><td>NULL</td><td>NULL</td><td>AVAX</td><td>0.00819324</td><td>28.95</td><td>1</td></tr>\n",
       "<tr><td>item_listed</td><td>item_listed</td><td>testseiberians9</td><td>2024-07-21 09:47:...</td><td>NULL</td><td>Unrevealed Seiber...</td><td>https://testnets....</td><td>sepolia/0xb37c71e...</td><td>https://i.seadn.i...</td><td>sepolia</td><td>2024-07-21 09:47:41</td><td>NULL</td><td>NULL</td><td>NULL</td><td>ETH</td><td>1.0</td><td>3494.29</td><td>1</td></tr>\n",
       "<tr><td>item_listed</td><td>item_listed</td><td>unidentified-cont...</td><td>2024-07-20 19:15:...</td><td>NULL</td><td>NULL</td><td>https://testnets....</td><td>avalanche_fuji/0x...</td><td>NULL</td><td>avalanche_fuji</td><td>2024-07-20 19:15:27</td><td>NULL</td><td>NULL</td><td>NULL</td><td>AVAX</td><td>0.00819324</td><td>28.95</td><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+--------------------+---------------+-------------------+------------+------------+----------+--------------+----------+---------+--------+\n",
       "|      event| event_type|     collection_slug|             sent_at|status|           item_name|            item_url|         item_nft_id|           image_url|item_blockchain|       listing_date|listing_type|from_account|to_account|payment_symbol| eth_price|usd_price|quantity|\n",
       "+-----------+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+--------------------+---------------+-------------------+------------+------------+----------+--------------+----------+---------+--------+\n",
       "|item_listed|item_listed|meta-croak-not-wi...|2024-07-20 15:36:...|  NULL|Meta Croak - Not ...|https://testnets....|sepolia/0x50976f5...|https://i.seadn.i...|        sepolia|2024-07-20 15:35:57|        NULL|        NULL|      NULL|           ETH|       1.0|  3505.51|       1|\n",
       "|item_listed|item_listed|         cyan-bayc-2|2024-07-20 15:43:...|  NULL|                NULL|https://testnets....|sepolia/0x300b105...|https://i.seadn.i...|        sepolia|2024-07-20 15:43:24|        NULL|        NULL|      NULL|           ETH|       1.0|  3505.51|       1|\n",
       "|item_listed|item_listed|unidentified-cont...|2024-07-20 19:01:...|  NULL|                NULL|https://testnets....|avalanche_fuji/0x...|                NULL| avalanche_fuji|2024-07-20 19:01:04|        NULL|        NULL|      NULL|          AVAX|0.00819324|    28.95|       1|\n",
       "|item_listed|item_listed|     testseiberians9|2024-07-21 09:47:...|  NULL|Unrevealed Seiber...|https://testnets....|sepolia/0xb37c71e...|https://i.seadn.i...|        sepolia|2024-07-21 09:47:41|        NULL|        NULL|      NULL|           ETH|       1.0|  3494.29|       1|\n",
       "|item_listed|item_listed|unidentified-cont...|2024-07-20 19:15:...|  NULL|                NULL|https://testnets....|avalanche_fuji/0x...|                NULL| avalanche_fuji|2024-07-20 19:15:27|        NULL|        NULL|      NULL|          AVAX|0.00819324|    28.95|       1|\n",
       "+-----------+-----------+--------------------+--------------------+------+--------------------+--------------------+--------------------+--------------------+---------------+-------------------+------------+------------+----------+--------------+----------+---------+--------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.filter((F.col(\"event_type\") == \"item_listed\")).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538dda47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>event</th><th>event_type</th><th>collection_slug</th><th>sent_at</th><th>status</th><th>item_name</th><th>item_url</th><th>image_url</th><th>item_blockchain</th><th>from_account</th><th>to_account</th><th>payment_symbol</th><th>eth_price</th><th>usd_price</th><th>quantity</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+----------+---------------+-------+------+---------+--------+---------+---------------+------------+----------+--------------+---------+---------+--------+\n",
       "|event|event_type|collection_slug|sent_at|status|item_name|item_url|image_url|item_blockchain|from_account|to_account|payment_symbol|eth_price|usd_price|quantity|\n",
       "+-----+----------+---------------+-------+------+---------+--------+---------+---------------+------------+----------+--------------+---------+---------+--------+\n",
       "+-----+----------+---------------+-------+------+---------+--------+---------+---------------+------------+----------+--------------+---------+---------+--------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events.filter((F.col(\"event_type\") == \"item_received_bid\")).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f59725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------------------------------------------------+--------------------------+------+------------------------------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+----------------+------------------------------------------+------------------------------------------+--------------+---------+---------+--------+\n",
      "|event           |event_type      |collection_slug                                   |sent_at                   |status|item_name                     |item_url                                                                                              |image_url                                                                            |item_blockchain |from_account                              |to_account                                |payment_symbol|eth_price|usd_price|quantity|\n",
      "+----------------+----------------+--------------------------------------------------+--------------------------+------+------------------------------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+----------------+------------------------------------------+------------------------------------------+--------------+---------+---------+--------+\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 10:56:57.687128|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/7                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x2491decde6f75e4e6da96356868b9c9b2f5e9642|NULL          |NULL     |NULL     |2       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:11:39.606561|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/9                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0xce50f5798b5e298631b9f6e3a608ebc989b260fe|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|testing-open-ticketing-ecosystem-event-1519       |2024-07-20 11:11:37.201808|NULL  |quo mollitia necessitatibus #6|https://testnets.opensea.io/assets/amoy/0x85378508142762ae1959923d137bd07c76e31eb2/6                  |https://i.seadn.io/s/raw/files/ad4b567b5e819f5eb9dc8588aeb6896f.png?w=500&auto=format|amoy            |0x0000000000000000000000000000000000000000|0xe25023190b2cdc109f2b1b710e582ac36c3770c5|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|development-open-ticketing-ecosystem-event-2792   |2024-07-20 11:02:37.302332|NULL  |atque repudiandae ut #12      |https://testnets.opensea.io/assets/amoy/0x668cba66c65aaef0579279c5a2a33b3c4a28aaf8/12                 |https://i.seadn.io/s/raw/files/ad4b567b5e819f5eb9dc8588aeb6896f.png?w=500&auto=format|amoy            |0x0000000000000000000000000000000000000000|0x0000000000000000000000000000000000000000|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|badgetokenfactory-8                               |2024-07-20 11:02:37.305275|NULL  |NULL                          |https://testnets.opensea.io/assets/base_sepolia/0x4ff5920f66638355bb26c915c3a93bedb5d75edd/120636     |NULL                                                                                 |base_sepolia    |0x0000000000000000000000000000000000000000|0x5568d637aefe29d939a724f64e0515b238353bfb|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:18:05.553575|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/9                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x67e5c33a98a8994c7c5fdb56c1250d329d5bc587|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|game-item-10                                      |2024-07-20 10:51:03.065537|NULL  |NULL                          |https://testnets.opensea.io/assets/gunzilla_testnet/0x4646bfacfe64cb27403ff58ae7cbf9398971f1a0/778189 |NULL                                                                                 |gunzilla_testnet|0x0000000000000000000000000000000000000000|0x8b0fd4433227184f3ccd2a4f77319afcc41628f1|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|badgetokenfactory-6                               |2024-07-20 11:12:02.78772 |NULL  |NULL                          |https://testnets.opensea.io/assets/base_sepolia/0x6cf0acc13418334384e9101e7345f355191dcffe/33         |NULL                                                                                 |base_sepolia    |0x0000000000000000000000000000000000000000|0xcb12102493e513ed5e32fbc36864569bad2812bd|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:12:01.749021|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/7                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x44c3db39dac942adce7b7de800d9f9112fb62fe1|NULL          |NULL     |NULL     |2       |\n",
      "|item_transferred|item_transferred|badgetokenfactory-6                               |2024-07-20 11:06:03.187242|NULL  |NULL                          |https://testnets.opensea.io/assets/base_sepolia/0x6cf0acc13418334384e9101e7345f355191dcffe/8          |NULL                                                                                 |base_sepolia    |0x0000000000000000000000000000000000000000|0xa43b30fb0333e5d68cbe36e20c6accab28f82cc3|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 10:57:07.718699|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/11                 |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x78360d942e7c91756356a3b7a2c0a241550d2e32|NULL          |NULL     |NULL     |20      |\n",
      "|item_transferred|item_transferred|game-item-10                                      |2024-07-20 10:57:07.783917|NULL  |NULL                          |https://testnets.opensea.io/assets/gunzilla_testnet/0x4646bfacfe64cb27403ff58ae7cbf9398971f1a0/778254 |NULL                                                                                 |gunzilla_testnet|0x0000000000000000000000000000000000000000|0xf21a6ed0571cdd72c3db15a92cfff513c78d82ae|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:15:05.659972|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/19                 |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0xaa5aa347a51312d93fd696c920918dcdf71d2fe8|NULL          |NULL     |NULL     |5       |\n",
      "|item_transferred|item_transferred|badgetokenfactory-6                               |2024-07-20 11:15:07.60746 |NULL  |NULL                          |https://testnets.opensea.io/assets/base_sepolia/0x6cf0acc13418334384e9101e7345f355191dcffe/35         |NULL                                                                                 |base_sepolia    |0x0000000000000000000000000000000000000000|0x7c785f94786bdc313b73928b23e8caf78315f01f|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|game-item-11                                      |2024-07-20 11:12:08.692784|NULL  |NULL                          |https://testnets.opensea.io/assets/gunzilla_testnet/0x9965db4bb1d21734efecd0fa48db89d9fe979bb5/1026729|NULL                                                                                 |gunzilla_testnet|0x0000000000000000000000000000000000000000|0x986d957d431bcdc105b9f125be10ecac4b49d093|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:12:09.509492|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/12                 |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0xa3bc1c700b67e4f976703281225731211a7dea83|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|game-item-11                                      |2024-07-20 11:00:08.464707|NULL  |NULL                          |https://testnets.opensea.io/assets/gunzilla_testnet/0x9965db4bb1d21734efecd0fa48db89d9fe979bb5/1026684|NULL                                                                                 |gunzilla_testnet|0x0000000000000000000000000000000000000000|0x986d957d431bcdc105b9f125be10ecac4b49d093|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:00:05.888941|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/7                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x98ffdaf705fd9bc2e2dc7a722dd8d2f48f9d7ff4|NULL          |NULL     |NULL     |2       |\n",
      "|item_transferred|item_transferred|degencard-5                                       |2024-07-20 11:05:39.852814|NULL  |NULL                          |https://testnets.opensea.io/assets/blast_sepolia/0x7adeda3b37de7ebe16cef7df92152cf7ef23e4f5/55803     |NULL                                                                                 |blast_sepolia   |0x0000000000000000000000000000000000000000|0xe2863d3b8c6b6e9fe9bf12064d588d6154050867|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:05:37.559194|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/7                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0xe3682f2d0e0996e6899ea43c913336d78ebab2fb|NULL          |NULL     |NULL     |2       |\n",
      "+----------------+----------------+--------------------------------------------------+--------------------------+------+------------------------------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+----------------+------------------------------------------+------------------------------------------+--------------+---------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_events.filter((F.col(\"event_type\") == \"item_transferred\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb2757",
   "metadata": {},
   "source": [
    "# Global Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frame = \"1 hour\"\n",
    "time_frame_txt = \"_\".join(time_frame.split())\n",
    "time_window = F.window(\"sent_at\", time_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b48d5",
   "metadata": {},
   "source": [
    "## Marketplace transactions stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23186720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- collection_slug: string (nullable = true)\n",
      " |-- sent_at: timestamp (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- item_name: string (nullable = true)\n",
      " |-- item_url: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- item_blockchain: string (nullable = true)\n",
      " |-- from_account: string (nullable = true)\n",
      " |-- to_account: string (nullable = true)\n",
      " |-- payment_symbol: string (nullable = true)\n",
      " |-- eth_price: string (nullable = true)\n",
      " |-- usd_price: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      "\n",
      "+----------------+----------------+--------------------------------------------------+--------------------------+------+------------------------------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+----------------+------------------------------------------+------------------------------------------+--------------+---------+---------+--------+\n",
      "|event           |event_type      |collection_slug                                   |sent_at                   |status|item_name                     |item_url                                                                                              |image_url                                                                            |item_blockchain |from_account                              |to_account                                |payment_symbol|eth_price|usd_price|quantity|\n",
      "+----------------+----------------+--------------------------------------------------+--------------------------+------+------------------------------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+----------------+------------------------------------------+------------------------------------------+--------------+---------+---------+--------+\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 10:56:57.687128|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/7                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x2491decde6f75e4e6da96356868b9c9b2f5e9642|NULL          |NULL     |NULL     |2       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:11:39.606561|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/9                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0xce50f5798b5e298631b9f6e3a608ebc989b260fe|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|testing-open-ticketing-ecosystem-event-1519       |2024-07-20 11:11:37.201808|NULL  |quo mollitia necessitatibus #6|https://testnets.opensea.io/assets/amoy/0x85378508142762ae1959923d137bd07c76e31eb2/6                  |https://i.seadn.io/s/raw/files/ad4b567b5e819f5eb9dc8588aeb6896f.png?w=500&auto=format|amoy            |0x0000000000000000000000000000000000000000|0xe25023190b2cdc109f2b1b710e582ac36c3770c5|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|development-open-ticketing-ecosystem-event-2792   |2024-07-20 11:02:37.302332|NULL  |atque repudiandae ut #12      |https://testnets.opensea.io/assets/amoy/0x668cba66c65aaef0579279c5a2a33b3c4a28aaf8/12                 |https://i.seadn.io/s/raw/files/ad4b567b5e819f5eb9dc8588aeb6896f.png?w=500&auto=format|amoy            |0x0000000000000000000000000000000000000000|0x0000000000000000000000000000000000000000|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|badgetokenfactory-8                               |2024-07-20 11:02:37.305275|NULL  |NULL                          |https://testnets.opensea.io/assets/base_sepolia/0x4ff5920f66638355bb26c915c3a93bedb5d75edd/120636     |NULL                                                                                 |base_sepolia    |0x0000000000000000000000000000000000000000|0x5568d637aefe29d939a724f64e0515b238353bfb|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:18:05.553575|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/9                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x67e5c33a98a8994c7c5fdb56c1250d329d5bc587|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|game-item-10                                      |2024-07-20 10:51:03.065537|NULL  |NULL                          |https://testnets.opensea.io/assets/gunzilla_testnet/0x4646bfacfe64cb27403ff58ae7cbf9398971f1a0/778189 |NULL                                                                                 |gunzilla_testnet|0x0000000000000000000000000000000000000000|0x8b0fd4433227184f3ccd2a4f77319afcc41628f1|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|badgetokenfactory-6                               |2024-07-20 11:12:02.78772 |NULL  |NULL                          |https://testnets.opensea.io/assets/base_sepolia/0x6cf0acc13418334384e9101e7345f355191dcffe/33         |NULL                                                                                 |base_sepolia    |0x0000000000000000000000000000000000000000|0xcb12102493e513ed5e32fbc36864569bad2812bd|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:12:01.749021|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/7                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x44c3db39dac942adce7b7de800d9f9112fb62fe1|NULL          |NULL     |NULL     |2       |\n",
      "|item_transferred|item_transferred|badgetokenfactory-6                               |2024-07-20 11:06:03.187242|NULL  |NULL                          |https://testnets.opensea.io/assets/base_sepolia/0x6cf0acc13418334384e9101e7345f355191dcffe/8          |NULL                                                                                 |base_sepolia    |0x0000000000000000000000000000000000000000|0xa43b30fb0333e5d68cbe36e20c6accab28f82cc3|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 10:57:07.718699|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/11                 |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x78360d942e7c91756356a3b7a2c0a241550d2e32|NULL          |NULL     |NULL     |20      |\n",
      "|item_transferred|item_transferred|game-item-10                                      |2024-07-20 10:57:07.783917|NULL  |NULL                          |https://testnets.opensea.io/assets/gunzilla_testnet/0x4646bfacfe64cb27403ff58ae7cbf9398971f1a0/778254 |NULL                                                                                 |gunzilla_testnet|0x0000000000000000000000000000000000000000|0xf21a6ed0571cdd72c3db15a92cfff513c78d82ae|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:15:05.659972|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/19                 |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0xaa5aa347a51312d93fd696c920918dcdf71d2fe8|NULL          |NULL     |NULL     |5       |\n",
      "|item_transferred|item_transferred|badgetokenfactory-6                               |2024-07-20 11:15:07.60746 |NULL  |NULL                          |https://testnets.opensea.io/assets/base_sepolia/0x6cf0acc13418334384e9101e7345f355191dcffe/35         |NULL                                                                                 |base_sepolia    |0x0000000000000000000000000000000000000000|0x7c785f94786bdc313b73928b23e8caf78315f01f|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|game-item-11                                      |2024-07-20 11:12:08.692784|NULL  |NULL                          |https://testnets.opensea.io/assets/gunzilla_testnet/0x9965db4bb1d21734efecd0fa48db89d9fe979bb5/1026729|NULL                                                                                 |gunzilla_testnet|0x0000000000000000000000000000000000000000|0x986d957d431bcdc105b9f125be10ecac4b49d093|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:12:09.509492|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/12                 |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0xa3bc1c700b67e4f976703281225731211a7dea83|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|game-item-11                                      |2024-07-20 11:00:08.464707|NULL  |NULL                          |https://testnets.opensea.io/assets/gunzilla_testnet/0x9965db4bb1d21734efecd0fa48db89d9fe979bb5/1026684|NULL                                                                                 |gunzilla_testnet|0x0000000000000000000000000000000000000000|0x986d957d431bcdc105b9f125be10ecac4b49d093|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:00:05.888941|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/7                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0x98ffdaf705fd9bc2e2dc7a722dd8d2f48f9d7ff4|NULL          |NULL     |NULL     |2       |\n",
      "|item_transferred|item_transferred|degencard-5                                       |2024-07-20 11:05:39.852814|NULL  |NULL                          |https://testnets.opensea.io/assets/blast_sepolia/0x7adeda3b37de7ebe16cef7df92152cf7ef23e4f5/55803     |NULL                                                                                 |blast_sepolia   |0x0000000000000000000000000000000000000000|0xe2863d3b8c6b6e9fe9bf12064d588d6154050867|NULL          |NULL     |NULL     |1       |\n",
      "|item_transferred|item_transferred|unidentified-contract-63e314b9-96d5-4cf7-b730-aca4|2024-07-20 11:05:37.559194|NULL  |NULL                          |https://testnets.opensea.io/assets/amoy/0x03122299579b9f1fd846c5cc9c7c2fe80ab34eba/7                  |NULL                                                                                 |amoy            |0xc50e4422b2d8a373ecfc95c21b7cd92b982c892d|0xe3682f2d0e0996e6899ea43c913336d78ebab2fb|NULL          |NULL     |NULL     |2       |\n",
      "+----------------+----------------+--------------------------------------------------+--------------------------+------+------------------------------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+----------------+------------------------------------------+------------------------------------------+--------------+---------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transferred_items = df_events.filter((F.col(\"event_type\") == \"item_transferred\"))\n",
    "transferred_items = transferred_items.withColumn(\n",
    "    \"quantity\", F.when(F.col(\"quantity\").cast(\"int\") > 0, F.col(\"quantity\").cast(\"int\")).otherwise(0)\n",
    ")\n",
    "transferred_items.printSchema()\n",
    "transferred_items.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a98d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 228:===================================================> (178 + 1) / 182]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+-----------------------+\n",
      "|window_start       |window_end         |transfers_count|items_transferred_count|\n",
      "+-------------------+-------------------+---------------+-----------------------+\n",
      "|2024-07-20 10:00:00|2024-07-20 11:00:00|4936           |57235                  |\n",
      "|2024-07-20 11:00:00|2024-07-20 12:00:00|11568          |9184401977             |\n",
      "+-------------------+-------------------+---------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "windowed_transactions = (\n",
    "    transferred_items\n",
    "    .groupBy(time_window)\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"transfers_count\"),\n",
    "        F.sum(\"quantity\").alias(\"items_transferred_count\"),\n",
    "    )\n",
    "    .orderBy(\"window\")\n",
    "    .select(\n",
    "        F.col(\"window.start\").alias(\"window_start\"),\n",
    "        F.col(\"window.end\").alias(\"window_end\"),\n",
    "        \"transfers_count\",\n",
    "        \"items_transferred_count\",\n",
    "    )\n",
    ")\n",
    "windowed_transactions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-------------------+----------+----------+\n",
      "|metric                         |timestamp          |value     |collection|\n",
      "+-------------------------------+-------------------+----------+----------+\n",
      "|transfers_count__1_hour        |2024-07-20 11:00:00|4936      |NULL      |\n",
      "|items_transferred_count__1_hour|2024-07-20 11:00:00|57235     |NULL      |\n",
      "|transfers_count__1_hour        |2024-07-20 12:00:00|11568     |NULL      |\n",
      "|items_transferred_count__1_hour|2024-07-20 12:00:00|9184401977|NULL      |\n",
      "+-------------------------------+-------------------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/20 13:15:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-68702f9a-49f7-4b3c-a4a4-14227d12cb09. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-68702f9a-49f7-4b3c-a4a4-14227d12cb09\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:173)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:109)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:359)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2120)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:95)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2310)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2310)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2216)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:686)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "windowed_transactions_events = windowed_transactions.unpivot(\n",
    "    [\"window_start\", \"window_end\"],\n",
    "    [\"transfers_count\", \"items_transferred_count\"],\n",
    "    \"metric\",\n",
    "    \"value\"\n",
    ").select(\n",
    "    F.concat(\"metric\", F.lit(f\"__{time_frame_txt}\")).alias(\"metric\"),\n",
    "    F.col(\"window_end\").alias(\"timestamp\"),\n",
    "    \"value\",\n",
    "    F.lit(None).alias(\"collection\"),\n",
    ")\n",
    "windowed_transactions_events.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3618862d",
   "metadata": {},
   "source": [
    "## Marketplace Sales Volume over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd04d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:====================================================> (176 + 1) / 182]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------+-----------+\n",
      "|window_start       |window_end         |usd_volume|sales_count|\n",
      "+-------------------+-------------------+----------+-----------+\n",
      "|2024-07-20 11:00:00|2024-07-20 12:00:00|0.534207  |1          |\n",
      "+-------------------+-------------------+----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sold_items = df_events.filter((F.col(\"event_type\") == \"item_sold\"))\n",
    "# Sales volume over time (Every hour)\n",
    "sold_items_hourly = (\n",
    "    sold_items.groupBy(time_window)\n",
    "    .agg(F.sum(\"usd_price\").alias(\"usd_volume\"), F.count(\"*\").alias(\"sales_count\"))\n",
    "    .orderBy(\"window\")\n",
    "    .select(\n",
    "        F.col(\"window.start\").alias(\"window_start\"),\n",
    "        F.col(\"window.end\").alias(\"window_end\"),\n",
    "        \"usd_volume\",\n",
    "        \"sales_count\",\n",
    "    )\n",
    ")\n",
    "sold_items_hourly.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58daca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>metric</th><th>timestamp</th><th>value</th><th>collection</th></tr>\n",
       "<tr><td>total_volume__1_hour</td><td>2024-07-20 12:00:00</td><td>0.534207</td><td>NULL</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-------------------+--------+----------+\n",
       "|              metric|          timestamp|   value|collection|\n",
       "+--------------------+-------------------+--------+----------+\n",
       "|total_volume__1_hour|2024-07-20 12:00:00|0.534207|      NULL|\n",
       "+--------------------+-------------------+--------+----------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sold_items_hourly_events = sold_items_hourly.select(\n",
    "    F.lit(f\"total_volume__{time_frame_txt}\").alias(\"metric\"),\n",
    "    F.col(\"window_end\").alias(\"timestamp\"),\n",
    "    F.col(\"usd_volume\").alias(\"value\"),\n",
    "    F.lit(None).alias(\"collection\"),\n",
    ")\n",
    "sold_items_hourly_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba7b419",
   "metadata": {},
   "source": [
    "## Top Collections by sales volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df566b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:==================================================>   (171 + 2) / 182]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-------------------+----------+-----------+-----------+\n",
      "|collection_slug|window_start       |window_end         |usd_volume|sales_count|window_rank|\n",
      "+---------------+-------------------+-------------------+----------+-----------+-----------+\n",
      "|hhhhhhhh1155   |2024-07-20 11:00:00|2024-07-20 12:00:00|0.534207  |1          |1          |\n",
      "+---------------+-------------------+-------------------+----------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "top_collections = (\n",
    "    sold_items.groupby(\"collection_slug\", time_window)\n",
    "    .agg(F.sum(\"usd_price\").alias(\"usd_volume\"), F.count(\"*\").alias(\"sales_count\"))\n",
    "    .orderBy(F.desc(\"usd_volume\"))\n",
    "    .select(\n",
    "        \"collection_slug\",\n",
    "        F.col(\"window.start\").alias(\"window_start\"),\n",
    "        F.col(\"window.end\").alias(\"window_end\"),\n",
    "        \"usd_volume\",\n",
    "        \"sales_count\",\n",
    "    )\n",
    ").withColumn(\n",
    "    \"window_rank\",\n",
    "    (\n",
    "        F.row_number().over(\n",
    "            Window.partitionBy(\"window_start\", \"window_end\").orderBy(\n",
    "                F.desc(\"usd_volume\")\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "top_collections.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95db212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:=================================================>    (168 + 1) / 182]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-------------------+--------+------------+\n",
      "|metric                           |timestamp          |value   |collection  |\n",
      "+---------------------------------+-------------------+--------+------------+\n",
      "|top_collections_by_volume__1_hour|2024-07-20 12:00:00|0.534207|hhhhhhhh1155|\n",
      "+---------------------------------+-------------------+--------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_collections_events = top_collections.select(\n",
    "    F.lit(f\"top_collections_by_volume__{time_frame_txt}\").alias(\"metric\"),\n",
    "    F.col(\"window_end\").alias(\"timestamp\"),\n",
    "    F.col(\"usd_volume\").alias(\"value\"),\n",
    "    F.col(\"collection_slug\").alias(\"collection\"),\n",
    ").filter(F.col(\"window_rank\") <= 10)\n",
    "top_collections_events.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc826a",
   "metadata": {},
   "source": [
    "# Collections Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ddac22",
   "metadata": {},
   "source": [
    "## Top Collections most valuable assets sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_collections_list = (\n",
    "    top_collections.select(\"collection_slug\")\n",
    "    .distinct()\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa316a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>sent_at</th><th>collection_slug</th><th>item_name</th><th>item_url</th><th>image_url</th><th>usd_price</th><th>window_start</th><th>window_end</th><th>rank_by_price</th></tr>\n",
       "<tr><td>2024-07-20 11:02:...</td><td>hhhhhhhh1155</td><td>web3game1155</td><td>https://testnets....</td><td>https://i.seadn.i...</td><td>0.534207000000000000</td><td>2024-07-20 11:00:00</td><td>2024-07-20 12:00:00</td><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+---------------+------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------+\n",
       "|             sent_at|collection_slug|   item_name|            item_url|           image_url|           usd_price|       window_start|         window_end|rank_by_price|\n",
       "+--------------------+---------------+------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------+\n",
       "|2024-07-20 11:02:...|   hhhhhhhh1155|web3game1155|https://testnets....|https://i.seadn.i...|0.534207000000000000|2024-07-20 11:00:00|2024-07-20 12:00:00|            1|\n",
       "+--------------------+---------------+------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_collections_sales = sold_items.filter(\n",
    "    F.col(\"collection_slug\").isin(top_collections_list)\n",
    ")\n",
    "top_collections_assets = (\n",
    "    top_collections_sales.join(\n",
    "        top_collections,\n",
    "        how=\"left\",\n",
    "        on=(\n",
    "            (\n",
    "                top_collections_sales[\"sent_at\"].between(\n",
    "                    top_collections[\"window_start\"], top_collections[\"window_end\"]\n",
    "                )\n",
    "            )\n",
    "            & (\n",
    "                top_collections_sales[\"collection_slug\"]\n",
    "                == top_collections[\"collection_slug\"]\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    .select(\n",
    "        top_collections_sales[\"sent_at\"],\n",
    "        top_collections_sales[\"collection_slug\"],\n",
    "        top_collections_sales[\"item_name\"],\n",
    "        top_collections_sales[\"item_url\"],\n",
    "        top_collections_sales[\"image_url\"],\n",
    "        top_collections_sales[\"usd_price\"],\n",
    "        top_collections[\"window_start\"],\n",
    "        top_collections[\"window_end\"],\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"rank_by_price\",\n",
    "        F.row_number().over(\n",
    "            Window.partitionBy(\"collection_slug\", \"window_start\", \"window_end\").orderBy(\n",
    "                F.desc(\"usd_price\")\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "top_collections_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dac038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:================================================>     (165 + 1) / 182]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-------------------+------------+--------------------+------------+------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+\n",
      "|metric                                |timestamp          |collection  |value               |asset_name  |asset_url                                                                           |image_url                                                                            |\n",
      "+--------------------------------------+-------------------+------------+--------------------+------------+------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+\n",
      "|collection_top_assets_by_price__1_hour|2024-07-20 12:00:00|hhhhhhhh1155|0.534207000000000000|web3game1155|https://testnets.opensea.io/assets/amoy/0xa4ddd7fc0aa18542134f44987ba3126e0b68de46/1|https://i.seadn.io/s/raw/files/4713d3ac2a64a6ad1768496f9e5fd3e6.jpg?w=500&auto=format|\n",
      "+--------------------------------------+-------------------+------------+--------------------+------------+------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_collections_assets_events = top_collections_assets.select(\n",
    "    F.lit(f\"collection_top_assets_by_price__{time_frame_txt}\").alias(\"metric\"),\n",
    "    F.col(\"window_end\").alias(\"timestamp\"),\n",
    "    F.col(\"collection_slug\").alias(\"collection\"),\n",
    "    F.col(\"usd_price\").alias(\"value\"),\n",
    "    F.col(\"item_name\").alias(\"asset_name\"),\n",
    "    F.col(\"item_url\").alias(\"asset_url\"),\n",
    "    \"image_url\",\n",
    ").filter(F.col(\"rank_by_price\") <= 20)\n",
    "top_collections_assets_events.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924dab6d",
   "metadata": {},
   "source": [
    "## Collection Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb13ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>collection_slug</th><th>window_start</th><th>window_end</th><th>floor_price</th><th>total_volume</th><th>avg_assets_price</th><th>total_sales</th></tr>\n",
       "<tr><td>hhhhhhhh1155</td><td>2024-07-20 11:00:00</td><td>2024-07-20 12:00:00</td><td>0.534207</td><td>0.534207</td><td>0.534207</td><td>1.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+-------------------+-------------------+-----------+------------+----------------+-----------+\n",
       "|collection_slug|       window_start|         window_end|floor_price|total_volume|avg_assets_price|total_sales|\n",
       "+---------------+-------------------+-------------------+-----------+------------+----------------+-----------+\n",
       "|   hhhhhhhh1155|2024-07-20 11:00:00|2024-07-20 12:00:00|   0.534207|    0.534207|        0.534207|        1.0|\n",
       "+---------------+-------------------+-------------------+-----------+------------+----------------+-----------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_collections_stats = top_collections_assets.groupby(\n",
    "    \"collection_slug\",\n",
    "    \"window_start\",\n",
    "    \"window_end\"\n",
    ").agg(\n",
    "    F.min(\"usd_price\").cast(\"double\").alias(\"floor_price\"),\n",
    "    F.sum(\"usd_price\").cast(\"double\").alias(\"total_volume\"),\n",
    "    F.avg(\"usd_price\").cast(\"double\").alias(\"avg_assets_price\"),\n",
    "    F.count(\"*\").cast(\"double\").alias(\"total_sales\"),\n",
    ")\n",
    "top_collections_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34527b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:===================================================> (176 + 1) / 182]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-------------------+------------+--------+----------+---------+---------+\n",
      "|metric                             |timestamp          |collection  |value   |asset_name|asset_url|image_url|\n",
      "+-----------------------------------+-------------------+------------+--------+----------+---------+---------+\n",
      "|collection_floor_price__1_hour     |2024-07-20 12:00:00|hhhhhhhh1155|0.534207|NULL      |NULL     |NULL     |\n",
      "|collection_total_volume__1_hour    |2024-07-20 12:00:00|hhhhhhhh1155|0.534207|NULL      |NULL     |NULL     |\n",
      "|collection_avg_assets_price__1_hour|2024-07-20 12:00:00|hhhhhhhh1155|0.534207|NULL      |NULL     |NULL     |\n",
      "|collection_total_sales__1_hour     |2024-07-20 12:00:00|hhhhhhhh1155|1.0     |NULL      |NULL     |NULL     |\n",
      "+-----------------------------------+-------------------+------------+--------+----------+---------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_collections_stats_events = top_collections_stats.unpivot(\n",
    "    [\"collection_slug\", \"window_start\", \"window_end\"],\n",
    "    [\"floor_price\", \"total_volume\", \"avg_assets_price\", \"total_sales\"],\n",
    "    \"metric\",\n",
    "    \"value\",\n",
    ").select(\n",
    "    F.concat(F.lit(\"collection_\"), F.col(\"metric\"), F.lit(f\"__{time_frame_txt}\")).alias(\"metric\"),\n",
    "    F.col(\"window_end\").alias(\"timestamp\"),\n",
    "    F.col(\"collection_slug\").alias(\"collection\"),\n",
    "    \"value\",\n",
    "    F.lit(None).alias(\"asset_name\"),\n",
    "    F.lit(None).alias(\"asset_url\"),\n",
    "    F.lit(None).alias(\"image_url\"),\n",
    ")\n",
    "top_collections_stats_events.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12631e93",
   "metadata": {},
   "source": [
    "## Merge both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:================================================>    (168 + 1) / 182]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-------------------+------------+--------------------+------------+------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+\n",
      "|metric                                |timestamp          |collection  |value               |asset_name  |asset_url                                                                           |image_url                                                                            |\n",
      "+--------------------------------------+-------------------+------------+--------------------+------------+------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+\n",
      "|collection_floor_price__1_hour        |2024-07-20 12:00:00|hhhhhhhh1155|0.534207            |NULL        |NULL                                                                                |NULL                                                                                 |\n",
      "|collection_total_volume__1_hour       |2024-07-20 12:00:00|hhhhhhhh1155|0.534207            |NULL        |NULL                                                                                |NULL                                                                                 |\n",
      "|collection_avg_assets_price__1_hour   |2024-07-20 12:00:00|hhhhhhhh1155|0.534207            |NULL        |NULL                                                                                |NULL                                                                                 |\n",
      "|collection_total_sales__1_hour        |2024-07-20 12:00:00|hhhhhhhh1155|1.0                 |NULL        |NULL                                                                                |NULL                                                                                 |\n",
      "|collection_top_assets_by_price__1_hour|2024-07-20 12:00:00|hhhhhhhh1155|0.534207000000000000|web3game1155|https://testnets.opensea.io/assets/amoy/0xa4ddd7fc0aa18542134f44987ba3126e0b68de46/1|https://i.seadn.io/s/raw/files/4713d3ac2a64a6ad1768496f9e5fd3e6.jpg?w=500&auto=format|\n",
      "+--------------------------------------+-------------------+------------+--------------------+------------+------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_collections_stats_events.union(top_collections_assets_events).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b72a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
